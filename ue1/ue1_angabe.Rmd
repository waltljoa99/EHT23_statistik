---
title: "MLE01 - Vertiefende statistische Verfahren"
subtitle: "1. Übungsblatt SS 2024"
author: "Stefan Kolb, Joachim Waltl"
output:
  pdf_document: default
  html_document:
    df_print: paged
  word_document: default 
---

# Allgemeine Information
Alle Aufgaben sind mit R zu lössen. Die Berechnungen sollen nachvollziehbar und dokumentiert sein. Um die vollständige Punktezahl zu erreichen, müssen alle Ergebnisse und Fragen entsprechend interpretiert bzw. beantwortet werden. Code alleine ist nicht ausreichend! Die Abgabe erfolgt über Moodle entsprechend der Abgaberichtlinien als pdf und Rmd File. Bitte inkludieren Sie namentlich alle beteiligten Gruppenmitglieder sowohl im Bericht als auch im Source Code.
Die jeweiligen Datensätze die für diese Übung relevant sind finden Sie ebenfalls in Moodle.

# 1 Lineare Regressionsanalyse [4P]
Für Menschen, die ihren Blutdruck senken wollen, ist eine häufig empfohlene Vorgehensweise, die Salzaufnahme zu senken. Sie möchten feststellen, ob es eine lineare Beziehung zwischen Salzaufnahme und Blutdruck gibt. Sie nehmen 52 Personen in die Stichprobe auf und messen deren diastolischen Blutdruck (in mmHg) und Natriumausscheidung (mmol/24h). [[ref](https://doi.org/10.1136/bmj.297.6644.319)]

**[2P] a:** Importieren Sie den Datensatz `intersalt.csv`. Erstellen Sie zwei Regressionsmodelle für den diastolische Blutdruck (bp) in Abhängigkeit der Natriumausscheidung (na). Das erste Modell soll alle Datenpunkte verwenden. Für das zweite Modell sollen die vier Datenpunkte mit der geringsten Natriumausscheidung aus dem Datensatz entfernt werden.

```{r}
get_path <- function(filename) {
  isRStudio <- Sys.getenv("RSTUDIO") == "1"
  if(isRStudio) {
     return(filename)
  }
  else {
    return(paste("ue1",filename,sep="/"))
  }
}
```

```{r}
# Display new plots in new tab
while(dev.cur() > 1) dev.off()
```

```{r}
 if (!is.null(Sys.getenv("RSTUDIO"))) {
  print("Running in RStudio")
 }

if (!is.null(Sys.getenv("VSCODE_PID"))) {
  print("Running in Visual Studio Code")
} else {
  print("Unknown IDE")
}
```

```{r}
# import intersalt data
intersalt <- read.csv(get_path("intersalt.csv"), sep = ";", dec = ",")

# summary of intersalt data
str(intersalt)

# first model (all data points)
model_1 <- lm(bp ~ na, data = intersalt)

# sort data by na
intersalt_sorted <- intersalt[order(intersalt$na),]

# new data set without the 4 smallest na values
intersalt_m2 <- intersalt_sorted[-c(1:4),]

# second model (without 4 smallest na values)
model_2 <- lm(bp ~ na, data = intersalt_m2)

# head of intersalt data
head(intersalt)

# mean of intersalt$na
mean(intersalt$na)

# 
```

Führen Sie für beide Modelle eine lineare Regressionsanalyse durch, die folgende Punkte umfasst:


i) Modellgleichung inklusive 95\% Konfidenzintervall der Modellparameter
i) Interpretation des Ergebnisses hinsichtlich Signifikanz und Modellgüte
i) Grafische Darstellung der Regressionsgeraden inkl. Konfidenzintervall


**Modell 1**
```{r}
# summary and confidence interval for model_1
summary(model_1)
confint(model_1)
```


i) Die Modellgleichung für das erste Modell lautet: bp = 67.56 [63.25;71.87] + 0.038 [0.01;0.07] * na. 

ii) Interpretation der Signifikanz und Modellgüte:

**Intercept:** Das 95\% Konfidenzintervall für den Intercept liegt zwischen 63.25123 und 71.87368. Das bedeutet, dass der diastolische Blutdruck bei einer Natriumausscheidung von 0 mmol/24h mit einer 95\%igen Sicherheit zwischen 63.25 und 71.87 mmHg liegt.

**Steigung:** Das 95\% Konfidenzintervall für die Steigung bezüglich der Natriumausscheidung liegt zwischen 0.00988 und 0.06548. Wir können also mit 95\%iger Sicherheit sagen, dass der Anstieg des diastolische Blutdruck zwischen 0.00988 und 0.06548 beträgt, wenn die Natriumausscheidung um 1 mmol/24h steigt.

**Signifikanz und Modellgüte:** 
Die Signifikanz des p-Wertes für die Steigung (p = 0.0089) deutet auf einen statistisch signifikanten Zusammenhang zwischen der Natriumausscheidung und dem diastolischen Blutdruck hin. Der p-Wert für den Intercept dieses Modells ist sogar als hochsignifikant zu werten. Ein Wert von 0.1291 für das Bestimmtheitsmaß R^2 zeigt jedoch, dass das Modell nur etwa 12.91\% der Variabilität im diastolischen Blutdruck mit der Natriumausscheidung erklären kann. Die Erkenntnis daraus ist, dass noch andere Faktor den Blutdruck beeinflussen. 

iii) Grafische Darstellung der Regressionsgeraden inkl. Konfidenzintervall

```{r}
# regression plot for model_1
library(ggplot2)
ggplot(intersalt, aes(x = na, y = bp)) +
  geom_point() +
  geom_smooth(method = "lm", se = TRUE) +
  labs(title = "Diastolischer Blutdruck in Abhängigkeit der Natriumausscheidung",
       x = "Natriumausscheidung (mmol/24h)",
       y = "Diastolischer Blutdruck (mmHg)")

```


**Modell 2**

```{r}  
# summary and confidence interval for model_2
summary(model_2)
confint(model_2)

```

i) Die Modellgleichung für das zweite Modell lautet: bp = 81.06 [74.40;87.72] - 0.045 [-0.09;0.00] * na.

ii) Interpretation der Signifikanz und Modellgüte: \newline

**Intercept:** Das 95% Konfidenzintervall für den Intercept liegt zwischen 74.40191 und 
87.72479. Das bedeutet, dass der diastolische Blutdruck laut diesem Modell bei einer hypothetischen Natriumausscheidung von 0 mmol/24h mit einer 95%igen Sicherheit zwischen 74.40 und 87.72 mmHg liegt.

**Steigung:** Das 95% Konfidenzintervall für die Steigung bezüglich der Natriumausscheidung liegt zwischen -0.08602 und -0.00337. In diesem Fall ist also von einer Abnahme des diastolischen Blutdrucks um 0.00337 bis 0.08602 mmHg auszugehen, wenn die Natriumausscheidung um 1 mmol/24h steigt. Im Gegensatz zum ersten Modell zeigt die Steigung hier also einen negativen Zusammenhang zwischen Natriumausscheidung und diastolischem Blutdruck.  

**Signifikanz und Modellgüte:** Auch bei diesem Modell ist der p-Wert für den Intercept hochsignifikant. Der p-Wert für die Steigung ist mit 0.035 zwar signifikant, aber deutlich weniger als der p-Wert für die Steigung des ersten Modells. Das Bestimmtheitsmaß R^2 beträgt hier 0.09, was bedeutet, dass das Modell nur etwa 9% der Variabilität im diastolischen Blutdruck mit der Natriumausscheidung erklären kann, wobei es beim ersten Modell noch knapp 13% waren.

iii) Grafische Darstellung der Regressionsgeraden inkl. Konfidenzintervall

```{r}
# regression plot for model_2
ggplot(intersalt_m2, aes(x = na, y = bp)) +
  geom_point() +
  geom_smooth(method = "lm", se = TRUE) +
  labs(title = "Diastolischer Blutdruck in Abhängigkeit der Natriumausscheidung (reduzierte Daten)",
       x = "Natriumausscheidung (mmol/24h)",
       y = "Diastolischer Blutdruck (mmHg)")
```

Vergleichen Sie beide Modelle. Was können Sie beobachten?

Die signifikante Änderung der Richtung des Effekts (von positiv zu negativ) nach dem Entfernen der vier Datenpunkte mit der niedrigsten Natriumausscheidung legt nahe, dass diese Datenpunkte einen erheblichen Einfluss auf das Gesamtergebnis des Modells haben.

Ein niedrigerer Wert für R^2 im zweiten Modell könnte bedeuten, dass die vier entfernten Datenpunkte tatsächlich einen wichtigen Beitrag zur Erklärung der Variabilität des diastolischen Blutdrucks leisten.

Trotz der signifikanten Koeffizienten in beiden Modellen bleiben die R^2 Werte relativ niedrig. Somit wird deutlich, dass noch weitere, hier nicht betrachtete Variablen einen Einfluss auf den diastolischen Blutdruck haben.

```{r}
# graphical comparison of both models
ggplot(intersalt, aes(x = na, y = bp)) +
  geom_point() +
  geom_smooth(method = "lm", se = TRUE, color = "blue") +
  geom_smooth(data = intersalt_m2, method = "lm", se = TRUE, color = "red") +
  labs(title = "Diastolischer Blutdruck in Abhängigkeit der Natriumausscheidung",
       x = "Natriumausscheidung (mmol/24h)",
       y = "Diastolischer Blutdruck (mmHg)",
       color = "Model") +
  scale_color_manual(values = c("blue", "red"))
```


**[2P] b:** Lesen Sie den Artikel "The (Political) Science of Salt" und vergleichen Sie damit Ihre Beobachtungen. Gibt es Faktoren die in Ihren Modellen eventuell nicht berücksichtigt wurden? Wie lautet die Schlussfolgerung - führt eine Reduktion der Salzaufnahme zu einer Blutdrucksenkung?

*Zusammenfassung des Artikels "The (Political) Science of Salt":*
Die Intersalt-Studie, eine standardisierte, internationale Untersuchung mit einer großen Stichprobe von über 10000 Teilnehmenden, bietet einen tiefgehenden Einblick in den Zusammenhang zwischen Salzaufnahme und Blutdruck. Die Ergebnisse variieren beträchtlich zwischen verschiedenen geografischen Regionen, wobei extrem niedrige Natriumwerte in einigen isolierten Gemeinschaften mit niedrigem Blutdruck und geringem altersbedingten Anstieg des Blutdrucks korrelierten. Im Gegensatz dazu zeigten andere Studienzentren signifikante Zusammenhänge zwischen Natriumausscheidung und Blutdruckanstieg. Obwohl die Studie einen Trend zu niedrigerem Blutdruck bei geringerer Salzaufnahme andeutet, sind die Ergebnisse durch die Heterogenität der teilnehmenden Populationen und die Vielzahl der berücksichtigten Einflussgrößen wie Body-Mass-Index und Alkoholkonsum komplex.

*Vergleich mit Intersalt-Studie:* Die Zusammenfassung der Intersalt-Studie deutet auf eine positive Assoziation zwischen Natriumausscheidung und Blutdruck hin, was konsistent mit den Erkenntnissen aus unserem ersten Modell ist. Die Studie fand auch signifikante positive Assoziationen nach Adjustierung auf Alter, Geschlecht und andere Faktoren wie Body-Mass-Index und Alkoholkonsum.

*Nicht berücksichtigte Faktoren:* In unserem Modell haben wir nur die Natriumausscheidung als Prädiktor für den Blutdruck betrachtet. Andere Faktoren, die in der Intersalt-Studie berücksichtigt wurden, wie Geschlecht, Body-Mass-Index, Alkoholkonsum und geografische Region, könnten ebenfalls einen Einfluss auf den Blutdruck haben und wurden in unseren 'simplen' Modellen nicht berücksichtigt.

*Schlussfolgerung hinsichtlich Salzaufnahme und Blutdrucksenkung:* In unserer Untersuchung konnten wir feststellen, dass ein erhöhter Salzkonsum tendenziell mit einem höheren (systolischen) Blutdruck einhergeht. Dies wird durch unser erstes Modell untermauert, das alle verfügbaren Datenpunkte berücksichtigt. Interessanterweise zeigte das zweite Modell, nach dem Ausschluss der vier niedrigsten Natriumaufnahmewerte, eine umgekehrte Beziehung, was die Sensitivität der Ergebnisse gegenüber Extremwerten verdeutlicht. Die Befunde der Intersalt-Studie bekräftigen grundsätzlich den positiven Zusammenhang zwischen Salzaufnahme und Blutdruck, insbesondere nach der Adjustierung um zusätzliche Variablen wie etwa Körpergewicht und Alkoholkonsum. Alle diese Variablen wurden in unseren Modellen nicht berücksichtigt, was etwaige Abweichungen zwischen den Studienergebnissen und unseren Analysen erklären könnte. In Anbetracht dieser Erkenntnisse erscheint es jedoch plausibel, dass die Reduzierung der Salzaufnahme einen günstigen Einfluss auf den Blutdruck hat.


# 2 Lineare Regressionsanalyse (kategorisch) [3P]
Der Datensatz `infant.csv` enthält Information über die unterschiedliche Kindersterblichkeit zwischen den Kontinenten. Die Variable `infant` enthält die Kindersterblichkeit in Tode pro 1000 Geburten. Unterscheidet sich die Kindersterblichkeit zwischen den Kontinenten?s

**[2P] a:** Führen Sie eine Regressionsanalyse mit Europa als Referenz durch, welche die folgenden Punkte umfasst:

i) Modellgleichung inklusive 95\% Konfidenzintervall der Modellparameter
i) Interpretation des Ergebnisses hinsichtlich Signifikanz
i) Beurteilung der Modellgüte und Residuenanalyse

```{r}
# Import the data
data <- read.csv2(get_path("infant.csv"))

# Convert the region variable to a factor
data$region <- as.factor(data$region)

# Set "Europe" as the reference level for the region variable
data$region <- relevel(data$region, ref = "Europe")

# Fit a linear model with infant as a function of region
model <- lm(infant ~ region, data = data)

# Print the model equation and 95% confidence intervals
summary(model)
confint(model, level=0.95)
```
Der p-Wert der F-Stastik liegt unter 5%&, was bedeuet, dass mindestens ein
Koeffizient signifikant ist.

Der p-Wert der erwarteten Kindersterblichkeit für Europa "(Intercept)" liegt
mit 31% über dem Signifikanzniveau von 5%. Dementsprechend ist 0 im
Konfidenzintervall eingeschlossen. D.h. es gibt keinen signfikanten Unterschied 
zu Kindersterblichkeit gleich 0.

Der p-Wert der erwarteten Differenz in der Kindersterblichkeit zwischen Europa
und Amerika "regionAmericas" liegt auch über 5%. D.h. es gibt keinen signifikanten
Unterschied in der Kindersterblichkeit zwischen Euorpa und Amerika.

Die p-Werte der erwareten Differenzen in der Kindersterblichkeit zwischen den
übrigen Regionen und Europa liegen unter 5%. Hier gibt es also, basierend auf den Daten dieser Stichprobe einen signfikanten Unterschied in der Kindersterblichkeit zu Europa.

Der adjusted R^2 beträgt 23%. Somit können 23% der Varianz in der (relativen)
Kindersterblichkeit durch eine Änderung in den (binären) Prädiktor-Variablen bestimmt werden.

```{r}
# Interpret the significance of the results

# The p-value for each term tests the null hypothesis that the coefficient is equal to zero (no effect).
# A low p-value (< 0.05) indicates that you can reject the null hypothesis.

# Assess the quality of the model and perform a residual analysis
#par(mfrow=c(2,2))
#plot(model)

# Convert model's data to a data frame
model_data <- data[complete.cases(data), ]  # remove rows with missing values
df <- data.frame(resid = resid(model), fitted = fitted(model),
                 region = model_data$region, infant = model_data$infant)

# Load ggplot2
library(ggplot2)

# plots of residual analysis
# 1. Residuals vs Fitted
p1 <- ggplot(df, aes(fitted, resid)) +
  geom_point() +
  #geom_smooth(se = FALSE) +
  ggtitle("1.) Residuum vs. Vorhergesagter Wert")

# 2. Normal Q-Q
p2 <- ggplot(df, aes(sample = resid)) +
  stat_qq() +
  stat_qq_line(colour = "red") +
  ggtitle("2.) Normal Q-Q-Plot")

# 3. Histogram of residuals
p3 <- ggplot(df, aes(x=resid)) +
  geom_histogram(binwidth = 10) +
  ggtitle("3.) Histogramm der Residuen")

# 4. Scatter Plot
p4 <- ggplot(df, aes(x=region, y=infant)) +
  geom_jitter(width=0.0) +
  ggtitle("Streudiagramm der Kindersterblichkeit nach Region")

# Load gridExtra
library(gridExtra)

# Arrange the plots in a 4x1 grid
grid.arrange(p1, p2, p3, p4, nrow = 2)

```
Die Region Asien zeigt 3 Ausreißer nach oben, die besonders ins Auge stechen.
Wenn man sie ignoriert, kann man eine annährende Normalverteilung der Residuen
beispielsweise im Q-Q-Plot und Histogramm erkennen.

Links oben: Die Residuen streuen normalverteilt um den Nullpunkt, allerdings
scheint die Standardabweichung der Residuen nach Region unterschiedlich zu sein.

Insgesamt entsteht aber der Eindruck, dass eine Normalverteilung der Residuen
vorliegt und ihre Varianz in etwa gleich bleibt
(d.h. Homoskedastizität gegeben ist). 

**[1P] b:** Wie hoch ist die Kindersterblichkeit in Europa und wie hoch in Afrika (inkl. Unsicherheit)?

```{r}
# Get the model coefficients and their confidence intervals
coef <- coef(model)
conf_int <- confint(model)
names(coef(model))

# Calculate the infant mortality rate for Europe
europe_coef <- coef["(Intercept)"]
europe_conf_int <- conf_int["(Intercept)", ]

# Calculate the infant mortality rate for Africa
africa_coef <- coef["regionAfrica"]
africa_conf_int <- conf_int["regionAfrica", ]

# Print the results
cat("Europa:\n")
cat("Anzahl: ", europe_coef, "\n")
cat("95% KI: ", europe_conf_int, "\n")

cat("Afrika:\n")
cat("Anzahl: ", africa_coef+europe_coef, "\n")
cat("95% KI: ", africa_conf_int+europe_coef, "\n")
```

# 3 Regressionsanalyse [3P]
Die Daten `wtloss.xlsx` enthalten den Gewichtsverlauf eines adipösen Patienten im Zuge einer Diät. Sie als betreuender Mediziner und passionierter Freizeit Data Scientist möchten ein geeignetes Regressionsmodell erstellen, um den Verlauf der Diät besser steuern zu können. Das ideale Zielgewicht bezogen auf die Größe des Patienten wäre bei 80 kg. Importieren Sie den Datensatz mit Hilfe der `read_excel()` Funktion aus dem `library(readxl)` Paket. 

**[2P] a:** Die Regressionsanalyse sollte folgende Punkte inkludieren:

i) Modellgleichung inklusive 95% Konfidenzintervall der Modellparameter
i) Interpretation des Ergebnisses hinsichtlich Signifikanz
i) Beurteilung der Modellgüte und Residuenanalyse
i) Grafische Darstellung der Regressionsgeraden inkl. Konfidenz-und Vorhersageinterval

```{r}
library(readxl)
# import the data
data <- read_excel(get_path("wtloss.xlsx"))

# fit a linear model
model <- lm(Weight ~ Days, data = data)

# print the model equation and 95% confidence intervals
summary(model)
confint(model, level=0.95)
```

Laut der p-Werte (p<0.01) und zugehörigen Konfidenzintervalle liefert das lineare Regressionsmodell hochsignfikante Ergebnisse für die Konstante und den Koeffizienten in
Weight = (Intercept) + Days * x

```{r}
# Convert model's data to a data frame
model_data <- data[complete.cases(data), ]  # remove rows with missing values
df <- data.frame(resid = resid(model), fitted = fitted(model),
                 Weight = model_data$Weight, Days = model_data$Days)

# Load ggplot2
library(ggplot2)

# Create the four diagnostic plots
# 1. Residuals vs Fitted
p1 <- ggplot(df, aes(fitted, resid)) +
  geom_point() +
  #geom_smooth(se = FALSE) +
  ggtitle("Residuum vs Vorhergesagter Wert")

# 2. Normal Q-Q
p2 <- ggplot(df, aes(sample = resid)) +
  stat_qq() +
  stat_qq_line(colour = "red") +
  ggtitle("Normal Q-Q-Plot")

# 3. Histogram of residuals
p3 <- ggplot(df, aes(x=resid)) +
  geom_histogram(binwidth = 0.5) +
  ggtitle("Histogramm der Residuen")

# 4. Scatter Plot
p4 <- ggplot(df, aes(x=Days, y=Weight)) +
  geom_jitter(width=0.0) +
  ggtitle("Streudiagramm Gewicht")

# Load gridExtra
library(gridExtra)

# Arrange the plots in a 4x1 grid
grid.arrange(p1, p2, p3, p4, nrow = 2)
```
Die Grafiken zeigen, dass die Residuen nicht normalverteilt sind. Sie zeigen ein Muster.
D.h. das linerare Modell ist nicht sehr gut geeignet für den Datensatz.
Zur weiteren Veranschaulichung erfolgt eine Darstellung des linearen Modells inklusive
Konfidenz- und Vorhersage-Intervall.

```{r}
# 1. Add predictions 
pred.int <- predict(model, interval = "prediction")
mydata <- cbind(data, pred.int)
# 2. Regression line + confidence intervals
library("ggplot2")
p <- ggplot(mydata, aes(x=Days, y=Weight)) +
  geom_point() +
  stat_smooth(method = lm)
# 3. Add prediction intervals
p + geom_line(aes(y = lwr), color = "red", linetype = "dashed")+
    geom_line(aes(y = upr), color = "red", linetype = "dashed")
```
Um ein besseres Regressionsmodell zu finden, wird R^2 and RMSE für das
lineare Modell, ein logarithmisches, ein quadratisches, kubisches und
ein Polynom 5. Grades berechnet. 

```{r}
# Load necessary library
library(caret)

# Drop the first row to avoid singularity in logarithmic model
new_data <- data[-1, ]

# Fit different types of models
linear_model <- lm(Weight ~ Days, data = data)
logarithmic_model <- lm(Weight ~ log(Days), data = new_data)
quadratic_model <- lm(Weight ~ poly(Days, 2), data = data)
cubic_model <- lm(Weight ~ poly(Days, 3), data = data)
fifth_order_model <- lm(Weight ~ poly(Days, 5), data = data)

# List of models
models <- list(linear_model, logarithmic_model, quadratic_model, cubic_model, fifth_order_model)

# Calculate R^2 and RMSE for each model
for (model in models) {
  # output title of model
  cat(paste("Model: ", deparse(model$call), "\n"))
  print(summary(model)$r.squared) # R^2
  print(summary(model)$adj.r.squared) # Adjusted R^2
  print(sqrt(mean(resid(model)^2))) # RMSE
  cat("\n")
}
```
Das quadratische Modell stellt eine hinreichende Verbesserung im Vergleich zum
linearen dar. Polynome höhrer Ordnung verbessern R^2 und RMSE nur geringfügig.
Um die Güte des quadratischen Modells zu beurteilen, erfolgt die Residualanalyse.

```{r}

# Calculate the logarithm of a column and overwrite the old values
log_data = data
log_data$Weight <- log(data$Weight)

# Convert model's data to a data frame
model_data <- data[complete.cases(data), ]  # remove rows with missing values
df <- data.frame(resid = resid(models[[3]]), fitted = fitted(models[[3]]),
                 Weight = log_data$Weight, Days = log_data$Days)

# Load ggplot2
library(ggplot2)

# Create the four diagnostic plots
# 1. Residuals vs Fitted
p1 <- ggplot(df, aes(fitted, resid)) +
  geom_point() +
  #geom_smooth(se = FALSE) +
  ggtitle("1.) Residuum vs Vorhergesagter Wert")

# 2. Normal Q-Q
p2 <- ggplot(df, aes(sample = resid)) +
  stat_qq() +
  stat_qq_line(colour = "red") +
  ggtitle("2.) Normal Q-Q-Plot")

# 3. Histogram of residuals
p3 <- ggplot(df, aes(x=resid)) +
  geom_histogram(binwidth = 0.5) +
  ggtitle("3.) Histogramm der Residuen")

# 4. Scatter Plot
p4 <- ggplot(df, aes(x=Days, y=Weight)) +
  geom_jitter(width=0.0) +
  ggtitle("Streudiagramm Gewicht")

# Load gridExtra
library(gridExtra)

# Arrange the plots in a 4x1 grid
grid.arrange(p1, p2, p3, p4, nrow = 2)
```
Die Grafiken zeigen, dass die Residuen normalverteilt sind und kein eindeutiges
Muster erkennen lassen. Das quadratische Modell ist daher hinreichend gut geeignet zur Modellierung dieser Daten.

**[1P] b:** Welches Gewicht hat der Patient nach 30 Tagen bzw. nach 200 Tagen Diät?

```{r}
# Define new data frame with the single x value
new_data <- data.frame(Days = c(30,200))

# Calculate predicted y value with confidence interval
confidence_interval <- predict(models[[1]], newdata = new_data, interval = "confidence")

# Calculate predicted y value with prediction interval
prediction_interval <- predict(models[[1]], newdata = new_data, interval = "prediction")

# Print the results
print(confidence_interval)
print(prediction_interval)
```
Laut dem linearen Modell beträgt das Gewicht des Patienten nach 30 Tagen 168.17 kg 
(Konfidenzintervall [166.54,169.80], Vorhersageintervall [160.68,175.66])
und nach 200 Tagen 118.74 kg
(Konfidenzintervall [117.21,120.28], Vorhersageintervall [111.27,126.21]).

```{r}
# Define new data frame with the single x value
new_data <- data.frame(Days = c(30,200))

# Calculate predicted y value with confidence interval
confidence_interval <- predict(models[[3]], newdata = new_data, interval = "confidence")

# Calculate predicted y value with prediction interval
prediction_interval <- predict(models[[3]], newdata = new_data, interval = "prediction")

# Print the results
print(confidence_interval)
print(prediction_interval)
```
Laut dem quadratischen Modell beträgt das Gewicht des Patienten nach 30 Tagen 170.26 kg 
(Konfidenzintervall [169.81,170.71], Vorhersageintervall [168.32,172.20])
und nach 200 Tagen 119.74 kg
(Konfidenzintervall [119.34,120.15], Vorhersageintervall [117.81,121.67]).

# 4 Multiple Regressionsanalyse [3P]
Die Framingham-Herz-Studie war ein Wendepunkt bei der Identifizierung von Risikofaktoren für koronare Herzkrankheiten und ist eine der wichtigsten epidemiologischen Studien die je durchgeführt wurden. Ein großer Teil unseres heutigen Verständnisses von Herz-Kreislauf-Erkrankungen ist auf diese Studie zurückzuführen. Der Datensatz `Framingham.sav` enthält Varibalen hinsichtlich Demographie, Verhaltensweise, Krankengeschichte und Risikofaktoren. Finden Sie ein geeignetes Modell, dass den systolischen Blutdruck (`sysbp`) beschreibt. Vermeiden Sie nicht relevante bzw. redundante Variablen (z.B. "Incident" Variablen). Achten Sie auf Ausreißer und fehlende Daten (`NaN, NA's`). 
 
**[2P] a:** Die Regressionsanalyse sollte folgende Punkte inkludieren:

i) Modellgleichung inklusive 95% Konfidenzintervall der Modellparameter
i) Interpretation des Ergebnisses hinsichtlich Signifikanz
i) Beurteilung der Modellgüte und Residuenanalyse

Die folgende Sektion ist nur eine experimentelle Vorarbeit und kein Teil der Antwort.
```{r}
# Import the data
# Load necessary library
library(haven)

# Read in .sav file
data <- read_spss(get_path("Framingham.sav"))

# check for missing values
sum(is.na(data))

# show rows with missing values
na_rows <- data[!complete.cases(data), ]

# Remove rows with missing values
data <- data[complete.cases(data), ]

# Fit a multivariate linear regression model with all variables
max_model <- lm(sysbp ~ ., data = data)

summary(max_model)

# Calculate confidence intervals for each variable
#conf_intervals <- confint(model,level=0.95)
#print(conf_intervals)

# Extract coefficients
coefficients <- coef(max_model)

# Calculate confidence intervals
conf_intervals <- confint(max_model, level = 0.95)

# Print coefficients and their confidence intervals
for (i in 1:length(coefficients)) {
  cat(names(coefficients)[i], ": ", coefficients[i], ", CI: [", conf_intervals[i, 1], ", ", conf_intervals[i, 2], "]\n")
}
```
Für das multiple Regressionsmodell wurden folgende Variablen mit eingeschlossen:
Geschlecht, Alter, Bildungsstand, Raucherstatus, Zigaretten pro Tag,
die Einnahme blutdrucksenkender Medikamente, Cholesterol, diastolischer Blutdruck,
Body Mass Index, Diagnose Diabetes, Herzrate und Glukosewert.
Davon sind Geschlecht, Bildungsstand, Raucherstatus,
die Einnahme blutdrucksenkender Medikamente und die Diagnose Diabetes
kategorialen Variablen.

```{r}
# analyse multicollinearity
library(car)
vif(max_model)

```
Die Multikollinearität ist in diesem Modell nicht signifikant, da alle Variablen einen VIF-Wert unter 5 haben. Am auffälligsten sind jedoch die Variablen "cursmoke" und "cigsperday", die möglicherweise aufgrund ihrer Korrelation einen hohen VIF-Wert aufweisen. Auch die Variablen mi_fchd und cvd 

```{r}
# Import the data
# Load necessary library
library(haven)

# Read in .sav file
data <- read_spss(get_path("Framingham.sav"))

# Convert the educ variable to a factor
data$educ <- as.factor(data$educ)

# Set "1" as the reference level for the educ variable
data$educ <- relevel(data$educ, ref = "1")

# Convert the sex variable to a factor
data$sex <- as.factor(data$sex)

# Set "1" as the reference level for the educ variable
data$sex <- relevel(data$sex, ref = "1")

# Convert the cursmoke variable to a factor
data$cursmoke <- as.factor(data$cursmoke)

# Set "0" as the reference level for the cursmoke variable
data$cursmoke <- relevel(data$cursmoke, ref = "0")

# Convert the bpmeds variable to a factor
data$bpmeds <- as.factor(data$bpmeds)

# Set "0" as the reference level for the bpmeds variable
data$bpmeds <- relevel(data$bpmeds, ref = "0")

# Convert the diabetes variable to a factor
data$diabetes <- as.factor(data$diabetes)

# Set "0" as the reference level for the diabetes variable
data$diabetes <- relevel(data$diabetes, ref = "0")

model <- lm(sysbp ~ sex + age + educ + cursmoke + cigpday + bpmeds + totchol + diabp + bmi + diabetes + heartrte + glucose, data = data)

summary(model)

# Extract coefficients
coefficients <- coef(model)

# Calculate confidence intervals
conf_intervals <- confint(model, level = 0.95)

# Print coefficients and their confidence intervals
for (i in 1:length(coefficients)) {
  cat(names(coefficients)[i], ": ", coefficients[i], ", CI: [", conf_intervals[i, 1], ", ", conf_intervals[i, 2], "]\n")
}
```
6 von 15 Modellparametern sind nicht signifikant. Diese sind
educ2 (High School) cursmoke1 (positiver Raucherstatus), cigpday (Zigaretten pro Tag),
totchol (Cholesterol), bmi (Body Mass Index) und diabetes1 (positive Diabetes Diagnose).

Auffällig ist der stark positive Wert von bpmeds1 (vorhandene Einnahme von Blutdrucksenkern).
Dieses hochsignifikatne Ergebnis ist auf den ersten Blick etwas überraschend, und bedeutet, dass die Einnahme von Blutdrucksenkern mit einem Anstieg des systolischen Blutdrucks einhergeht. Dies könnte jedoch durch die Tatsache erklärt werden, dass Personen, die Blutdrucksenker einnehmen, bereits einen hohen Blutdruck haben, der durch die Medikation kontrolliert werden soll. Es ist daher wichtig, dieses Ergebnis im Kontext der vorliegenden Daten und des medizinischen Hintergrunds zu interpretieren.

Auch bemerkenswert ist der Einfluss des Geschlechts auf den systolischen Blutdruck. Der Koeffizient für sex2 ist positiv und hochsignifikant, was bedeutet, dass Frauen basierend auf den Daten in unserem Modell einen höheren systolischen Blutdruck haben als Männer.

```{r}
# Convert model's data to a data frame
model_data <- data[complete.cases(data), ]  # remove rows with missing values
df <- data.frame(resid = resid(model), fitted = fitted(model),
                 sysbp = model_data$sysbp, sex = model_data$sex, age = model_data$age, educ = model_data$educ, cursmoke = model_data$cursmoke, cigpday = model_data$cigpday, bpmeds = model_data$bpmeds, totchol = model_data$totchol, diabp = model_data$diabp, bmi = model_data$bmi, diabetes = model_data$diabetes, heartrte = model_data$heartrte, glucose = model_data$glucose)

# Load ggplot2
library(ggplot2)

# Create a function to generate scatter plots
scatter_plot <- function(df, x_var, y_var = "sysbp", title) {
  ggplot(df, aes_string(x = x_var, y = y_var)) +
    geom_jitter(width = 0.0) +
    ggtitle(title)
}

# Create the four diagnostic plots
p1 <- ggplot(df, aes(fitted, resid)) +
  geom_point() +
  ggtitle("Residuum vs Vorhergesagter Wert")

p2 <- ggplot(df, aes(sample = resid)) +
  stat_qq() +
  stat_qq_line(colour = "red") +
  ggtitle("Normal Q-Q-Plot")

p3 <- ggplot(df, aes(x=resid)) +
  geom_histogram(binwidth = 5) +
  ggtitle("Histogramm der Residuen")

# Create scatter plots using the function
p4 <- scatter_plot(df, "sex", title = "Geschlecht")
p5 <- scatter_plot(df, "educ", title = "Bildung")
p6 <- scatter_plot(df, "cursmoke", title = "Raucher")
p7 <- scatter_plot(df, "cigpday", title = "Zigaretten")
p8 <- scatter_plot(df, "bmi", title = "BMI")
p9 <- scatter_plot(df, "bpmeds", title = "Blutdrucksenker")
p10 <- scatter_plot(df, "totchol", title = "Cholesterol")
p11 <- scatter_plot(df, "diabp", title = "Diast. Blutdruck")
p12 <- scatter_plot(df, "diabetes", title = "Diabetes")
p13 <- scatter_plot(df, "heartrte", title = "Herzrate")
p14 <- scatter_plot(df, "glucose", title = "Glukose")

# Arrange the plots
grid.arrange(p1, p2, p3, nrow = 1)
grid.arrange(p7, p8, p10, p11, p13, p14, nrow = 2)
grid.arrange(p4, p5, p6, p9, p12, nrow = 2)
```
Selbst wenn man die 4 stärksten Ausreißer unter den Residuen größer 55 entfernt,
bleibt ersichtlich, dass die Verteilung der Residuen rechtsschief ist.
Die Güte des Modells ist daher fragwürdig.

*Multiple R-Quadrat:* Das multiple R-Quadrat von 0,693 deutet darauf hin, dass das Modell in etwa 69,3% der Varianz in der Zielvariablen (systolischer Blutdruck) erklären kann.

*Adjustiertes R-Quadrat:* Mit 0,6919 liegt das adjustierte R-Quadrat sehr nahe am multiplen R-Quadrat, was darauf hindeutet, dass das Modell nicht übermäßig komplex für die Menge der verfügbaren Daten ist und eine angemessene Anzahl an Prädiktoren aufweist.

*F-Statistik:* Die F-Statistik ist sehr hoch mit einem sehr kleinen p-Wert, was darauf hinweist, dass das Modell insgesamt signifikant ist.

*Plots der Residuen:*

Residuum vs. Vohersage: Idealerweise sollten die Residuen zufällig um die 0-Linie verteilt sein. Es scheint eine gewisse Heteroskedastizität vorzuliegen, da die Varianz der Residuen mit steigenden vorhergesagten Werten scheinbar zunimmt.\newline
Normal Q-Q-Plot: Die Punkte folgen der Referenzlinie nicht genau, insbesondere in den Enden der Verteilung. Dies deutet darauf hin, dass die Residuen nicht perfekt normalverteilt sind.\newline
Histogramm der Residuen: Das Histogramm sieht relativ normalverteilt aus, eine leichte Rechtsschiefe ist jedoch erkennbar.


**[1P] b:** Welchen systolischen Blutdruck hat eine Person mit folgendem Profil:

Frau, 50 Jahre, High School, Raucher, 8 Zig/Tag, keine Blutdruck senkenden Medikamente, 220 mg/dl Serum Cholesterol, 85 mmHg diastolischer Blutdruck, BMI von 30, kein Diabetes, 90 bpm Herzrate und Glukoselevel von 90 mg/dl.

```{r}
# Create a new data frame that contains the person's profile
new_data <- data.frame(
  sex = factor("2", levels = c("1","2")), # Female
  age = 50,
  educ = factor("2", levels = c("1","2","3","4")), # High School
  cursmoke = factor("1", levels = c("0","1")), # Yes
  cigpday = 8,
  bpmeds = factor("0", levels = c("0","1")), # No
  totchol = 220,
  diabp = 85,
  bmi = 30,
  diabetes = factor("0", levels = c("0","1")), # No
  heartrte = 90,
  glucose = 90
)

# Predict the systolic blood pressure
predicted_sysbp <- predict(model, newdata = new_data)

print(predicted_sysbp)

# Get the confidence interval for the predicted value
predicted_sysbp_conf_int <- predict(model, newdata = new_data, interval = "confidence")
print(predicted_sysbp_conf_int)

# Get the prediction interval for the predicted value
predicted_sysbp_pred_int <- predict(model, newdata = new_data, interval = "prediction")
print(predicted_sysbp_pred_int)
```
Der systolische Blutdruck der Person mit dem gegebenen Profil beträgt 138.4 mmHg
(Konfidenzintervall [137.1,139.7], Vorhersageintervall [114.0,162.9]).

