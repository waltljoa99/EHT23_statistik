---
title: "Vertiefende statistische Verfahren"
subtitle: "4. Übungsblatt SS 2024"
author: "Stefan Kolb, Joachim Waltl"

output:
  pdf_document: default
  html_document:
    df_print: paged
  word_document: default
---

```{r setup, include=FALSE}
## Run this chunk ALWAYS first !
# Arbeitsverzeichnis für VSC Nutzer korrekt setzen
# Nötige Packages installieren und laden
# Helfer Funktionen für alle Nutzer laden

# Set relative path to target working directory
rel_path_to_target_dir <- "ue4"
# Helper file name
rel_path_from_target_dir_to_helper_file <- "helper.R"

# Check if the code is run in RStudio
checkIDEisRStudio <- function() {
  isRStudio <- Sys.getenv("RSTUDIO") == "1"
  if (isRStudio) {
    return(TRUE)
  } else {
    return(FALSE)
  }
}

# Check whether package is already installed, if not install it
load <- function(package_name) {
  if (length(find.package(package_name, quiet = TRUE)) == 0) {
    # Set the CRAN mirror
    options(repos = c(CRAN = "https://cran.wu.ac.at/"))
    install.packages(package_name)
  }
  suppressWarnings(library(package_name, character.only = TRUE))
}

# The working directory is only changed if the code is NOT run in RStudio
if (!checkIDEisRStudio()) {
  load("here")
  # Change relative path accordingly to your target working directory
  abs_path_to_target_dir <- file.path(here(),rel_path_to_target_dir)
  # Check if target directory exists
  if(dir.exists(abs_path_to_target_dir)){
    setwd(abs_path_to_target_dir)
  }
}

# Load packages
load("pROC")
load("caret")
load("ResourceSelection")
load("foreign")
load("haven")
load("tidyverse")
load("car")
load("MVN")
load("ggplot2")
load("stats")
load("ROCit")
load("ggpubr")
load("nparLD")
load("rcompanion")
load("FSA")
load("MASS")
load("dplyr")
load("heplots")
load("klaR")
load("mda")
load("biotools")
load("psych")
load("FactoMineR")
load("factoextra")
load("gridExtra")


# Function to source helper file
load_source <- function() {
    if(!checkIDEisRStudio()){
      if(file.exists(rel_path_from_target_dir_to_helper_file)){
        source(rel_path_from_target_dir_to_helper_file)
      }
    } else {
      helper_file <- basename(rel_path_from_target_dir_to_helper_file)
      if(file.exists(helper_file)){
        source(helper_file)
      }
  }
}
# Apply function to source helper file
load_source()

```

# Allgemeine Information
Alle Aufgaben sind mit R zu lössen, wenn nicht explizit anders angegeben. Die Berechnungen sollen nachvollziehbar und dokumentiert sein. Um die vollständige Punktezahl zu erreichen, müssen alle Ergebnisse und Fragen entsprechend interpretiert bzw. beantwortet werden. Code alleine ist nicht ausreichend! Die Abgabe erfolgt über Moodle entsprechend der Abgaberichtlinien als pdf und Rmd File. Bitte inkludieren Sie namentlich alle beteiligten Gruppenmitglieder sowohl im Bericht als auch im Source Code.
Die jeweiligen Datensätze die für diese Übung relevant sind finden Sie ebenfalls in Moodle.

# (Aufgabe 1) Datensatz: Reaven and Miller Diabetes Daten
Verwenden Sie den Datensatz `diabetes_RM.csv`. Der Datensatz enthält fünf Messungen, die an 145 nicht adipösen erwachsenen Patienten durchgeführt wurden, die in drei Gruppen eingeteilt wurden.

```{r}
# Datensatz laden
diabetes <- read.csv("diabetes_RM.csv")

# Übersicht
str(diabetes)
head(diabetes)

# Outcomevariable als Faktor definieren
diabetes$group <- as.factor(diabetes$group)

# Zusammenfassung
summary(diabetes)

pairs.panels(diabetes[1:5],
             gap = 0,
             bg = c("green","red","blue")[diabetes$group],
             pch = 21)


```
Die drei primären Variablen sind die Glukoseintoleranz, die Insulinantwort auf orale Glukose und die Insulinresistenz (gemessen durch die Steady-State-Plasmaglukose, die nach chemischer Suppression der endogenen Insulinsekretion bestimmt wird). Zwei zusätzliche Variablen, das relative Gewicht und die Nüchternplasmaglukose, sind ebenfalls enthalten. Zusammengefasst ergeben sich folgende Prädiktorvariablen:

* `rw`: relatives Gewicht, Verhältnis zwischen aktuellem Gewicht und zu erwartendem Gewicht bei der Körpergröße
* `fpg`: Nüchternglukoselevel im Plasma in mg/dl 
* `glucose`: Fläche unter Glukose-Antwort (mg/dl*h) nach 3h oralem Glukosetoleranztest (OGTT) 
* `insulin`: Fläche unter der Insulin-Antwort (mg/dl*h) nach OGTT
* `sspg`: Steady-State-Plasmaglukose (mg/dl) als Maß für die Insulinresistenz

```{r}
# Variable Beschreibungen
descriptions <- get_descriptions()
```

Reaven und Miller [[ref]](https://doi.org/10.1007/BF00423145) wendeten in Anlehnung an Friedman und Rubin (1967) eine Clusteranalyse auf die drei primären Variablen an und identifizierten drei Cluster: "normal", "chemical" und "overt" diabetsiche Probanden. Die Variable `group` enthält die Klassifizierungen der Probanden in diese drei Gruppen. 

# 1 Diskriminanzanalyse [5P]
Führen Sie eine Diskriminanzanalyse unter Berücksichtigung folgender Punkte durch:

i) Explorative Analyse der Prädiktoren mit Hilfe von Histogrammen. Gibt es Prädiktoren, die bereits eine gute Trennung zwischen den Klassen erlauben?

```{r}
# Explorative Analyse

# Mittelwerte aller Gruppe für numerische Prädiktoren berechnen 

# Tabelle
aggregate(cbind(glucose,insulin,fpg,sspg,rw)~group,diabetes,mean)

# Histogramme
create_histograms(diabetes)
```
Anhand der Histogramme lässt sich kein Prädiktor identifizieren, der eine klare Trennung zwischen den Klassen erlaubt. Am ehesten ist beim Prädiktor 'glucose' eine Abgrenzung der Gruppen zu erkennen.

```{r}
# Explorativer Ansatz zur Trennung der Gruppen
# Grenzen anhand des Prädiktors 'glucose' 
grenzen <- c(425,600)

ggplot(diabetes, aes(x = glucose, fill = group)) +
    geom_histogram(position = "identity", alpha = 0.5, bins = 30) +
    labs(x = "glucose", y = "Count", fill = "group") +
    # Grenze einfügen
    geom_vline(xintercept = grenzen, linetype = "dashed", color = "black") +
    theme_minimal()

# Klassifizierung der Gruppen anhand der Grenzen
diabetes$group_K1<- ifelse(diabetes$glucose < grenzen[1], "normal",
                             ifelse(diabetes$glucose < grenzen[2], "chemical",
                                    "overt"))

# Genauigkeit der Klassifizierung
mean(diabetes$group_K1 == diabetes$group)

```
Durch die Klassifizierung anhand des Prädiktors 'glucose' konnte eine Genauigkeit von knapp 96% erreicht werden. Dies deutet darauf hin, dass der Prädiktor 'glucose' tatsächlich bereits eine recht gute Trennung der Gruppen ermöglicht. Im nächsten Schritt wird eine Diskriminanzanalyse (LDA) durchgeführt, um hoffentlich eine noch akuratere Klassifizierung der Gruppen zu erreichen.

ii) Überprüfen Sie ob die Vorraussetzungen für eine LDA gegeben sind und führen Sie eine Standardisierung der Daten durch.

```{r}
# Überprüfen der Voraussetzungen

# Normalverteilung der Prädiktoren (Visuell u. Konservativ)

print("p-Werte des Shapiro-Wilk-Tests: ")
for (i in 1:5) {
  
  #Shapiro-Wilk-Test
  sw_p <- shapiro.test(diabetes[,i])$p.value
  print(paste("p-Wert für", colnames(diabetes)[i], ":", sw_p))
  
  
  par(mfrow = c(1,2))
  # Histogramme
  hist(diabetes[,i], main = colnames(diabetes)[i], xlab = "")
   for (j in 1:length(descriptions[[i]])) {
    mtext(descriptions[[i]][j], side = 1, line = 1 + j, cex = 0.8, col =   "blue")
  }
  # QQ-Plots
  qqnorm(diabetes[,i])
  qqline(diabetes[,i])
  
}

# Überprüfung der Multivariaten Normalverteilung
mvn_test <- MVN::mvn(diabetes[, sapply(diabetes, is.numeric)], mvnTest = "hz")
print(mvn_test)

```

In den Histogrammen und QQ-Plots ist zu erkennen, dass die Prädiktoren 'glucose', 'fpg' und 'insulin' deutliche Abweichungen von der Normalverteilung aufweisen. Ihre Verteilungen zeigen eine starke Rechtsschiefe und in den QQ-Plots sind deutliche Abweichungen von der Normalverteilung ersichtlich, insbesondere in den oberen Quantilen.

Die Prädiktoren 'sspg' und 'rw' sind hingegen annähernd normalverteilt.
```{r}
# Transformieren der Daten
diabetes_trans <- diabetes %>%
  mutate(glucose  = log(glucose+1),
         fpg = log(fpg+1),
         sspg  = log(sspg + 1),
         insulin = log(insulin + 1),
         rw = sqrt(rw),
         group = as.factor(group))

# Überprüfung der Transformation
pairs.panels(diabetes_trans[1:5],
             gap = 0,
             bg = c("green","red","blue")[diabetes_trans$group],
             pch = 21)

```
Auch der Multivariate Normalverteilungstest zeigt, dass die Daten nicht multivariat normalverteilt sind.

Selbst nach der Transformation der Daten sind die Prädiktoren 'glucose', 'fpg' und 'insulin' noch immer nicht normalverteilt. Die Diskriminanzanalyse wird dennoch durchgeführt, da sie robust gegenüber Verletzungen der Normalverteilung ist.

```{r}
# Korrelationen
cor_matrix <- cor(diabetes[,1:5])
print(cor_matrix)
```

Die Korrelationsmatrix zeigt, dass der Prädiktor 'glucose' eine starke positive Korrelation mit den Prädiktoren 'fpg'(0.96) und 'sspg'(0.77) aufweist.

```{r} 
# Kovarianzen
cov_matrix <- cov(diabetes[,1:5])
print(cov_matrix)

```

```{r}
# Überprüfung der Homogenität der Kovarianzen
boxM_test <- boxM(diabetes[, sapply(diabetes, is.numeric)], diabetes$group)
print(boxM_test)
```

Der Box-M-Test zeigt, dass die Kovarianzmatrizen der Gruppen nicht gleich sind. Dies bedeutet, dass die Annahme der Homogenität der Kovarianzmatrizen verletzt ist.
Streng genommen sind die Voraussetzungen für eine LDA nicht gegeben. Da die LDA in Klassifizierungsaufgaben jedoch robust gegenüber Verletzungen der Normalverteilung und Homogenität der Kovarianzen ist, wird die LDA dennoch durchgeführt.

Um eine bessere Vergleichbarkeit der Prädiktoren zu gewährleisten, werden die Daten standardisiert.

```{r}
# Standardisierung der Daten (mittels preProcess-Funktion)
diabetes.prePro <- preProcess(diabetes[, sapply(diabetes, is.numeric)], method = c("center", "scale"))
# Anwenden des Preprocessers
diabetes.pre <- predict(diabetes.prePro, diabetes[, sapply(diabetes, is.numeric)])
# Hinzufügen der Gruppe
diabetes.pre$group <- as.factor(diabetes$group)

# Alternative: Standardisieren in data.frame (mittels Scale-Funktion)(Transformierte Daten)
diabetes_trans.pre1<-data.frame(rw=scale(diabetes_trans$rw),
                         fpg=scale(diabetes_trans$fpg),
                         glucose=scale(diabetes_trans$glucose),
                         insulin=scale(diabetes_trans$insulin),
                         sspg=scale(diabetes_trans$sspg),
                         group=diabetes_trans$group)

```
iii) Unterteilen sie die gesamten Daten in Trainings- und Test-Daten und führen Sie in der weiteren Folge eine Klassifizierung mit einer LDA durch. Evaluieren Sie die Perfomance der Klassifizierung und stellen Sie die Ergebnisse graphisch dar (Darstellung der Projektionen, Partition Plot).

```{r}
# Splitten der Daten in Trainings- und Testdaten (80/20)
set.seed(42) # Für Reproduzierbarkeit

trainIndex <- sample(1:145, 0.8 * 145, replace = FALSE)
trainData <- diabetes.pre[ trainIndex,]
testData  <- diabetes.pre[-trainIndex,]

# Splitten der transformierten Daten
set.seed(42) 
trainIndex <- sample(1:145, 0.8 * 145, replace = FALSE)
trainData_t <- diabetes_trans.pre1[ trainIndex,]
testData_t <- diabetes_trans.pre1[-trainIndex,]

```

Nachdem die Daten in Trainings- und Testdaten aufgeteilt wurden, wird die LDA durchgeführt.

```{r}
# LDA (Daten ohne Transformation)
lda_m1 <- lda(group ~ glucose + fpg + insulin + sspg + rw, data = trainData)
# LDA (Daten mit Transformation)
lda_m2 <- lda(group ~ glucose + fpg + insulin + sspg + rw, data = trainData_t)

    # LDA nur mit Hauptvariablen
    lda_gis <- lda(group ~ glucose + rw + insulin + sspg, data = trainData)
    lda_gis.p <- predict(lda_gis, newdata = trainData)

# Zusammenfassung des Modells
lda_m1
lda_m2
lda_gis

# Klasse der Trainingsdaten vorhersagen
lda_m1.p <- predict(lda_m1, newdata = trainData)
lda_gis.p <- predict(lda_gis, newdata = trainData)
lda_m2.p <- predict(lda_m2, newdata = trainData_t)

head(lda_m1.p$posterior)
head(lda_m1.p$class)
    
# Genauigkeit des Modells überprüfen
print(paste("Model 1 (alle Parameter):",mean(lda_m1.p$class == trainData_t$group)))
print(paste("Model 2 (trans. Parameter):",mean(lda_m2.p$class == trainData_t$group)))
print(paste("Model 3 (nur Hauptparameter):",mean(lda_gis.p$class == trainData_t$group)))

```

Da durch das Modell mit den transformierten Daten eine höhere Genauigkeit erreicht werden konnte, wird neben dem Model 1 auch dieses Modell für die weitere Analyse und Klassifikation der Testdaten verwendet. 

```{r}
#lda Trennung darstellen
# Partition Plot
partimat(group ~ glucose + fpg + insulin + sspg + rw,
         data = diabetes.pre, method = "lda",
         image.colors = c("aquamarine", "gray", "darkorange"))

# Projektionen
lda_m1.p$x #LD1 und LD2

# lda_m1.p$x als data.frame
lda_m1.p$x <- as.data.frame(lda_m1.p$x)

#projektionen graphisch darstellen
ggplot(lda_m1.p$x, aes(x = LD1, y = LD2, color = trainData$group)) +
  geom_point() +
  ggtitle("LDA Projektionen (Trainingsdaten)") +
  xlab("LD1") +
  ylab("LD2") +
  theme_minimal()

# Histogramme der Projektionen
ldahist(lda_m1.p$x[,1], g = trainData$group,type = "both")
ldahist(lda_m1.p$x[,2], g = trainData$group, type = "both")

```

```{r}
# Vorhersage auf Testdaten
lda_pred <- predict(lda_m1, newdata = testData)
lda_pred2 <- predict(lda_m2, newdata = testData_t)

head(lda_pred$posterior)
head(lda_pred$class)

# Genauigkeit des Modells überprüfen
ac_lda <-mean(lda_pred$class == testData$group) # 93%
ac_lda_t <-mean(lda_pred2$class == testData_t$group) # 90%

# Projektionen der Testdaten 
lda_pred$x #LD1 und LD2

# lda_m1.p$x als data.frame
lda_pred$x <- as.data.frame(lda_pred$x)

#projektionen graphisch darstellen
ggplot(lda_pred$x, aes(x = LD1, y = LD2, color = testData$group)) +
  geom_point() +
  ggtitle("LDA Projektionen (Testdaten)") +
  xlab("LD1") +
  ylab("LD2") +
  theme_minimal()

# Histogramme der Projektionen
ldahist(lda_pred$x[,1], g = testData$group,type = "both")
ldahist(lda_pred$x[,2], g = testData$group, type = "both")

```
Die Klassifikationsgenauigkeit von Modell 1 beträgt auf den Testdaten 93%. Somit performt das Modell auf den Testdaten etwas besser als auf den Trainingsdaten, da diese nur zu 90% richtig klassifiziert wurden. Erstaunlich ist, dass der anfänglich untersuchte, explorative Ansatz einer Klassifikation über einen einfachen Schwellwert der Glucose-Variable zu einer höheren Klassifikationsgenauigkeit führte. 

Das Modell 2, welches die transformierten Daten verwendet, erreicht auf den Testdaten eine Klassifikationsgenauigkeit von 90% und auf den Trainingsdaten eine Genauigkeit von 93%. 

iiii) Vergleichen Sie unterschiedliche Varianten der Diskriminanzanalyse (QDA, MDA, FDA) hinsichtlich ihrer Klassifikationsgenauigkeit.

```{r}
#quadratische QDA
m_qda <- qda(group ~ glucose + fpg + insulin + sspg + rw, data = trainData)
m_qda.p <- predict(m_qda, newdata = testData)
ac_qda <- mean(m_qda.p$class == testData$group) # 0.90

#MDA
library(mda)
m_mda <- mda(group ~ glucose + fpg + insulin + sspg + rw, data = trainData)
m_mda.p <- predict(m_mda, newdata = testData)
ac_mda <- mean(m_mda.p== testData$group) # 0.90

#FDA
m_fda <- fda(group ~ glucose + fpg + insulin + sspg + rw, data = trainData)
m_fda.p <- predict(m_fda, newdata = testData)
ac_fda <-mean(m_fda.p == testData$group) # 0.93

#RDA
m_rda <- rda(group ~ glucose + fpg + insulin + sspg + rw, data = trainData)
m_rda.p <- predict(m_rda, newdata = testData)
ac_rda <- mean(m_rda.p$class == testData$group) # 0.93

# Tabelle
results <- data.frame(Model = c("LDA","LDA_T", "QDA", "MDA", "FDA", "RDA"),
                      Genauigkeit = c(ac_lda, ac_lda_t, ac_qda, ac_mda, ac_fda, ac_rda))
print(results)
```
Sowohl die FDA als auch die RDA erreichen ebenfalls eine Klassifikationsgenauigkeit von 93% auf den Testdaten. Die QDA, MDA sowie die LDA mit transformierten Daten erreichen nur eine Genauigkeit von etwa 90%.

# 2 Principal Component Analyse [5P]
Führen Sie eine PCA unter Berücksichtigung folgender Punkte durch:

i) Überprüfung der paarweisen Kovarianzen / Korrelationen

```{r}
# Load data
diabetes <- read.csv("diabetes_RM.csv")

# Overview
str(diabetes)
head(diabetes)

# Calculate variance for each numeric column
variances <- sapply(diabetes[sapply(diabetes, is.numeric)], var)
print(variances)

# Calculate covariance between all pairs of numeric columns
covariances <- cov(diabetes[sapply(diabetes, is.numeric)])
print(covariances)

# Select only numeric variables, excluding 'group'
numeric_vars <- sapply(diabetes, is.numeric)
numeric_vars["group"] <- FALSE

# Compute the correlation matrix
cor_matrix <- cor(diabetes[numeric_vars])

# Print the correlation matrix
print(cor_matrix)
```

Die Kovarianzmatrix zeigt, dass es Korrelationen zwischen unterschiedlichen Variablen gibt:
Nicht-Diagonal-Elemente ungleich 0.


ii) Berechnen der PCA und Beurteilung wie viele PCs sinnvoll sind (Eigenwerte und Screeplot).

```{r}

# Perform PCA
pca_result <- prcomp(diabetes[sapply(diabetes, is.numeric)], scale. = TRUE)

# Print summary of the PCA result
print(summary(pca_result))

# Eigenvalues (variances of the principal components)
eigenvalues <- pca_result$sdev^2
print(eigenvalues)

# Scree plot
scree_df <- data.frame(PC = 1:length(eigenvalues), eigenvalues = eigenvalues)
ggplot(data = scree_df, aes(x = PC, y = eigenvalues)) +
  geom_line() +
  geom_point() +
  scale_x_continuous(breaks = 1:length(eigenvalues)) +
  labs(title = "Scree Plot", x = "Principal Component", y = "Eigenvalue")
```

Da PCA1 und PCA2 bereits 82% der totalen Streuung erklären, können zwei (maximal 3 (96%)) PCs sinnvoll sein.

iii) Transformation der ursprünglichen Daten in ein PC-Koordinatensystem mit zwei PCs. Vergleichen Sie die Darstellung mit dem Ergebnis der LDA (LD1 und LD2 Projektionen).

Im Folgenden werden zuerst die LDA Projektionen der kombinierten Daten aus Training und Test gezeigt.

```{r}
# Add group information to lda_m1.p$x and lda_pred$x
lda_m1.p$x$group <- trainData$group
lda_pred$x$group <- testData$group

# Add a new variable to indicate the data source
lda_m1.p$x$data_source <- "Training Data"
lda_pred$x$data_source <- "Test Data"

# Combine the data frames
combined_data <- rbind(lda_m1.p$x, lda_pred$x)

# Create the combined plot
combined_plot <- ggplot(combined_data, aes(x = LD1, y = LD2, color = group)) +
  geom_point(aes(shape = data_source)) +
  ggtitle("LDA Projections (All Data)") +
  xlab("LD1") +
  ylab("LD2") +
  theme_minimal()

print(combined_plot)

```

Nun machen wir einen Vergleich zwischen den LDA-Projektionen und den PCA-Projektionen.

```{r}
# Perform PCA
pca_result <- prcomp(diabetes[sapply(diabetes, is.numeric)], scale. = TRUE)

# Extract the scores of the first two PCs
PC1_scores <- pca_result$x[,1]
PC2_scores <- pca_result$x[,2]

# Create a new data frame with the scores of the first two PCs
transformed_data <- data.frame(PC1 = PC1_scores, PC2 = PC2_scores)

# Add group information to the transformed data
transformed_data$group <- diabetes$group


# First plot (PCA scatter plot)
plot1 <- ggplot(transformed_data, aes(x = PC1, y = PC2, color = group)) +
  geom_point() +
  xlim(-10, 10) +
  ylim(-5, 5) +
  xlab("PC1") +
  ylab("PC2") +
  ggtitle("PCA Scatter plot") +
  theme_minimal()

# This plot is commented out because it only shows the training data

# Seconde plot (LDA scatter plot)
# plot2 <- ggplot(lda_m1.p$x, aes(x = LD1, y = LD2, color = trainData$group)) +
#   geom_point() +
#   xlim(-10, 10) +
#   ylim(-5, 5) +
#   ggtitle("LDA Projections (Training Data)") +
#   xlab("LD1") +
#   ylab("LD2") +
#   theme_minimal()

# Second plot (LDA scatter plot)
plot2 <- ggplot(combined_data, aes(x = LD1, y = LD2, color = group)) +
  geom_point(aes(shape = data_source)) +
  xlim(-10, 10) +
  ylim(-5, 5) +
  ggtitle("LDA Projections (All Data)") +
  xlab("LD1") +
  ylab("LD2") +
  theme_minimal()

grid.arrange(plot1, plot2, ncol = 2)

# Print the transformed data
# print(transformed_data)
```

Die Plots sehen sehr ähnlich aus, mit dem Unterschied, dass sie zueinander gespiegelt erscheinen.

iii) Stellen Sie den Correlation Circle und Biplot graphisch dar. Welche Information liefert diese Darstellung?

```{r}
# Perform PCA
pca_result <- prcomp(diabetes[sapply(diabetes, is.numeric)], scale. = TRUE)

# Plot the correlation circle
fviz_pca_var(pca_result, col.var="contrib", gradient.cols = c("#00AFBB", "#E7B800", "#FC4E07"), repel = TRUE)

# Plot the biplot
fviz_pca_biplot(pca_result, col.var="#2E9FDF", col.ind="#696969")
```

Correlation Circle:

Die Länge der Vektoren (0 bis 1) zeigt die Stärke der Korrelation zwischen den Variablen und den PCA-Achsen.
Die Normalprojektion der Vektoren auf die Achsen zeigt die Korrelation zwischen den Prädiktoren und den jeweiligen Achsen.
Da die ersten zwei PCA-Dimensionsn etwa 82% der totalen Streuung erklären, sind die Vektoren hinreichend nahe bei 1.
Am geringsten ist die Korrelation zwischen den Variablen rw und insulin und den PCA-Achsen, da sie die kürzesten Vektoren haben.

Biplot:

Es ist gut erkennbar, dass die Streuung der Datenpunkte um die PCA1-Achse (55% der totalen Streuung) stärker ist 
als die Streuung um die PCA2-Achse (28% der totalen Streuung). Die Vektoren der Variablen glucose und fpg zeigen
in Richtung der PCA1-Achse, was für eine starke Korrelation zwischen diesen Variablen und der PCA1-Achse spricht.
Dasselbe gilt für die Vektoren der Variablen insulin und rw für die PCA2-Achse.


iiii) Beurteilen Sie die Qualität und Beiträge der Variablen auf die PCs.

Die Variablen fpg, glucose und sspg tragen am stärksten zu den PCAs bei. glucose und fpg tragen am stärksten zu PCA1 bei.
Bei fpg, glucose, sspg und rw besteht eine positive Korrelation zu PCA1.
Die Variablen insulin und rw tragen am stärksten zu PCA2 bei und korrelieren positiv mit PCA2.
insulin korreliert gut erkennbar negativ mit PCA1, während fpg und glucose leicht negativ mit PCA2 korrelieren.


iiiii) Wiederholen Sie die LDA von Aufgabe 1 unter Verwendung der PCs zur Klassifizierung. Achten Sie auf die Verwendung der gleichen Trainings- und Test-Daten und vergleichen Sie die Performance. Vergleichen Sie weiters die Performance der LDA mit den Variablen `glucose` und `fpg` mit der PCA+LDA mit zwei PCs.

# Diskriminanzanalyse mit PCA Scores
Führen Sie eine Diskriminanzanalyse unter Berücksichtigung folgender Punkte durch:

i) Explorative Analyse der Prädiktoren mit Hilfe von Histogrammen. Gibt es Prädiktoren, die bereits eine gute Trennung zwischen den Klassen erlauben?

```{r}
# Datensatz laden
diabetes <- read.csv("diabetes_RM.csv")

# Perform PCA
pca_result <- prcomp(diabetes[sapply(diabetes, is.numeric)], scale. = TRUE)

# Extract the scores of the first two PCs
PC1 <- pca_result$x[,1]
PC2 <- pca_result$x[,2]

# Create a new data frame with the scores of the first two PCs
pca_scores <- data.frame(PC1 = PC1, PC2 = PC2)

# Add labels to PCA scores
pca_scores$group <- diabetes$group

# Assuming `pca_scores` is a data frame with your PCA scores
# and `group` is a factor variable indicating the group of each observation

# Calculate means of principal components for each group
aggregate(cbind(PC1, PC2) ~ group, pca_scores, mean)

# Create histograms
# You would need to define or adapt the `create_histograms()` function to work with PCA scores
create_histograms(pca_scores)
```

Anhand der Histogramme lässt sich erkennen, dass PC2 nicht als Trennungskriterium geeignet ist, da die Gruppen sich stark überlappen.
Allerdings lässt ich die "overt" Gruppe bei PC1 gut von den anderen Gruppen abgrenzen.


ii) Überprüfen Sie ob die Vorraussetzungen für eine LDA gegeben sind und führen Sie eine Standardisierung der Daten durch.

```{r}
# Überprüfen der Voraussetzungen

descriptions <- get_descriptions()

# Normalverteilung der Prädiktoren (Visuell u. Konservativ)

print("p-Werte des Shapiro-Wilk-Tests: ")
for (i in 1:2) {
  
  #Shapiro-Wilk-Test
  sw_p <- shapiro.test(pca_scores[,i])$p.value
  print(paste("p-Wert für", colnames(pca_scores)[i], ":", sw_p))
  
  
  par(mfrow = c(1,2))
  # Histogramme
  hist(pca_scores[,i], main = colnames(pca_scores)[i], xlab = "")

  # QQ-Plots
  qqnorm(pca_scores[,i])
  qqline(pca_scores[,i])
  
}

# Überprüfung der Multivariaten Normalverteilung
mvn_test <- MVN::mvn(pca_scores[, sapply(pca_scores, is.numeric)], mvnTest = "hz")
print(mvn_test)

```

In den Histogrammen und QQ-Plots ist zu erkennen, dass die PC2 Scores normalverteilt sind (p-Wert>0.05),
allerdings sind die PC1 Scores nicht normalverteilt (p-Wert nahezu 0).

```{r}
# Transformieren der Daten
pca_scores_trans <- pca_scores %>%
  mutate(PC1 = log(PC1 - min(PC1) + 1),
         PC2 = log(PC2 - min(PC2) + 1),
         group = as.factor(group))

# Überprüfung der Transformation
pairs.panels(pca_scores_trans[,1:2],
             gap = 0,
             bg = c("green","red","blue")[pca_scores_trans$group],
             pch = 21)
```
Auch der Multivariate Normalverteilungstest zeigt, dass die Daten nicht multivariat normalverteilt sind.

Selbst nach der log Transformation der Daten sind die PC Scores noch immer nicht normalverteilt. Die Diskriminanzanalyse wird dennoch durchgeführt, da sie robust gegenüber Verletzungen der Normalverteilung ist.

```{r}
# Korrelationen
cor_matrix <- cor(pca_scores[,1:2])
print(cor_matrix)
```

```{r} 
# Kovarianzen
cov_matrix <- cov(pca_scores[,1:2])
print(cov_matrix)

```

Die Korrelations/Kovarianzmatrix zeigt erwartungsgemäß, dass die Nicht-Diagonal-Elemente bei 0 liegen.
Das ist so, weil die PC Vektoren eine orthogonale Basis bilden und daher nicht miteinander korrelieren.

```{r}
# Überprüfung der Homogenität der Kovarianzen
boxM_test <- boxM(pca_scores[, sapply(pca_scores, is.numeric)], pca_scores$group)
print(boxM_test)
```

Der Box-M-Test zeigt, dass die Kovarianzmatrizen der Gruppen nicht gleich sind. Dies bedeutet, dass die Annahme der Homogenität der Kovarianzmatrizen verletzt ist.
Streng genommen sind die Voraussetzungen für eine LDA nicht gegeben. Da die LDA in Klassifizierungsaufgaben jedoch robust gegenüber Verletzungen der Normalverteilung und Homogenität der Kovarianzen ist, wird die LDA dennoch durchgeführt.

PCA Scores von standardisierten Daten sollten nicht nochmal standardisiert werden.

iii) Unterteilen sie die gesamten Daten in Trainings- und Test-Daten und führen Sie in der weiteren Folge eine Klassifizierung mit einer LDA durch. Evaluieren Sie die Perfomance der Klassifizierung und stellen Sie die Ergebnisse graphisch dar (Darstellung der Projektionen, Partition Plot).

```{r}
# Splitten der Daten in Trainings- und Testdaten (80/20)
set.seed(42) # Für Reproduzierbarkeit

trainIndex <- sample(1:145, 0.8 * 145, replace = FALSE)
trainData <- pca_scores[ trainIndex,]
testData  <- pca_scores[-trainIndex,]

# Splitten der transformierten Daten
set.seed(42) 
trainIndex <- sample(1:145, 0.8 * 145, replace = FALSE)
trainData_t <- pca_scores_trans[ trainIndex,]
testData_t <- pca_scores_trans[-trainIndex,]
```

Nachdem die Daten in Trainings- und Testdaten aufgeteilt wurden, wird die LDA durchgeführt.

```{r}
# LDA (Daten ohne Transformation)
lda_m1 <- lda(group ~ PC1 + PC2, data = trainData)
# LDA (Daten mit Transformation)
lda_m2 <- lda(group ~ PC1 + PC2, data = trainData_t)

# Zusammenfassung des Modells
lda_m1
lda_m2

# Klasse der Trainingsdaten vorhersagen
lda_m1.p <- predict(lda_m1, newdata = trainData)
lda_m2.p <- predict(lda_m2, newdata = trainData_t)

head(lda_m1.p$posterior)
head(lda_m1.p$class)
    
# Genauigkeit des Modells überprüfen
print(paste("Model 1 (PCs):",mean(lda_m1.p$class == trainData$group)))
print(paste("Model 2 (trans. PCs):",mean(lda_m2.p$class == trainData_t$group)))

```

Da durch das Modell mit den log transformierten Daten keine höhere Genauigkeit erreicht werden konnte, wird nur Model 1 auch für die weitere Analyse und Klassifikation der Testdaten herangezogen. 

```{r}
#lda Trennung darstellen

# Group variable to factor
trainData$group <- as.factor(trainData$group)


# Partition Plot
partimat(group ~ PC1 + PC2,
         data = trainData, method = "lda",
         image.colors = c("aquamarine", "gray", "darkorange"))

# Projektionen
lda_m1.p$x #LD1 und LD2

# lda_m1.p$x als data.frame
lda_m1.p$x <- as.data.frame(lda_m1.p$x)

#projektionen graphisch darstellen
ggplot(lda_m1.p$x, aes(x = LD1, y = LD2, color = trainData$group)) +
  geom_point() +
  ggtitle("LDA Projektionen (Trainingsdaten)") +
  xlab("LD1") +
  ylab("LD2") +
  theme_minimal()

# Histogramme der Projektionen
ldahist(lda_m1.p$x[,1], g = trainData$group,type = "both")
ldahist(lda_m1.p$x[,2], g = trainData$group, type = "both")
```


Die Klassifikationsgenauigkeit von Modell 1 beträgt auf den Testdaten 75%. Somit performt das Modell auf den Testdaten schlechter als auf den Trainingsdaten, da diese zu 84% richtig klassifiziert wurden.

```{r}
# Prediction on test data
lda_pred <- predict(lda_m1, newdata = testData)

# Check the head of the posterior probabilities and predicted classes
head(lda_pred$posterior)
head(lda_pred$class)

# Check the accuracy of the model
ac_lda <- mean(lda_pred$class == testData$group) # 75%
ac_lda

# Projections of the test data 
lda_pred$x #LD1 and LD2

# Convert lda_m1.p$x to a data.frame
lda_pred$x <- as.data.frame(lda_pred$x)

# Graphical representation of the projections
ggplot(lda_pred$x, aes(x = LD1, y = LD2, color = testData$group)) +
  geom_point() +
  ggtitle("LDA Projections (Test Data)") +
  xlab("LD1") +
  ylab("LD2") +
  theme_minimal()


# Histograms of the projections
ldahist(lda_pred$x[,1], g = testData$group, type = "both")
# ldahist(lda_pred$x[,2], g = testData$group, type = "both")

# The ldahist method is not suitable LDA2 because there are too few unique observations in the groups.
# Adjusting the bin width parameter h couldn't solve the problem.
# Therefore, we us ggplot instead.
ggplot(lda_pred$x, aes(x=LD2, fill=testData$group)) +
  geom_histogram(position="identity", alpha=0.5, bins=30) +
  theme_minimal() +
  xlab("LD2") +
  ylab("Count") +
  ggtitle("Histogram of LD2 Projections")
```


iiii) Vergleichen Sie unterschiedliche Varianten der Diskriminanzanalyse (QDA, MDA, FDA) hinsichtlich ihrer Klassifikationsgenauigkeit.

```{r}
# QDA
m_qda <- qda(group ~ PC1 + PC2, data = trainData)
m_qda.p <- predict(m_qda, newdata = testData)
ac_qda <- mean(m_qda.p$class == testData$group)

# MDA
library(mda)
m_mda <- mda(group ~ PC1 + PC2, data = trainData)
m_mda.p <- predict(m_mda, newdata = testData)
ac_mda <- mean(m_mda.p == testData$group)

# FDA
m_fda <- fda(group ~ PC1 + PC2, data = trainData)
m_fda.p <- predict(m_fda, newdata = testData)
ac_fda <- mean(m_fda.p == testData$group)

# RDA
m_rda <- rda(group ~ PC1 + PC2, data = trainData)
m_rda.p <- predict(m_rda, newdata = testData)
ac_rda <- mean(m_rda.p$class == testData$group)

# Table
results <- data.frame(Model = c("QDA", "MDA", "FDA", "RDA"),
                      Accuracy = c(ac_qda, ac_mda, ac_fda, ac_rda))
print(results)
```

Nur die FDA erreicht eine Klassifikationsgenauigkeit von etwa 83% wie die LDA auf den Testdaten. Alle anderen Modelle sind unterlegen.
