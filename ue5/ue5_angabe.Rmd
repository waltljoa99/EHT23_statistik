---
title: "Vertiefende statistische Verfahren"
subtitle: "5. Übungsblatt SS 2024"
author:
output:
  pdf_document: default
  html_document:
    df_print: paged
  word_document: default
---

```{r, include=FALSE}
## Run this chunk ALWAYS first !
# Arbeitsverzeichnis für VSC Nutzer korrekt setzen
# Nötige Packages installieren und laden
# Helfer Funktionen für alle Nutzer laden

# Set relative path to target working directory
rel_path_to_target_dir <- "ue5"
# Helper file name
rel_path_from_target_dir_to_helper_file <- "helper.R"

# Check if the code is run in RStudio
checkIDEisRStudio <- function() {
  isRStudio <- Sys.getenv("RSTUDIO") == "1"
  if (isRStudio) {
    return(TRUE)
  } else {
    return(FALSE)
  }
}

# Check whether package is already installed, if not install it
load <- function(package_name) {
  if (length(find.package(package_name, quiet = TRUE)) == 0) {
    # Set the CRAN mirror
    options(repos = c(CRAN = "https://cran.wu.ac.at/"))
    install.packages(package_name)
  }
  suppressWarnings(library(package_name, character.only = TRUE))
}

# The working directory is only changed if the code is NOT run in RStudio
if (!checkIDEisRStudio()) {
  load("here")
  # Change relative path accordingly to your target working directory
  abs_path_to_target_dir <- file.path(here(),rel_path_to_target_dir)
  # Check if target directory exists
  if(dir.exists(abs_path_to_target_dir)){
    setwd(abs_path_to_target_dir)
  }
}

# Load packages
load("cluster")
load("factoextra")
load("clusterCrit")
load("fpc")
load("mclust")
load("dplyr")
load("klaR")
load("ggplot2")
load("dbscan")

# Function to source helper file
load_source <- function() {
    if(!checkIDEisRStudio()){
      if(file.exists(rel_path_from_target_dir_to_helper_file)){
        source(rel_path_from_target_dir_to_helper_file)
      }
    } else {
      helper_file <- basename(rel_path_from_target_dir_to_helper_file)
      if(file.exists(helper_file)){
        source(helper_file)
      }
  }
}
# Apply function to source helper file
load_source()

```



# Allgemeine Information
Alle Aufgaben sind mit R zu lössen, wenn nicht explizit anders angegeben. Die Berechnungen sollen nachvollziehbar und dokumentiert sein. Um die vollständige Punktezahl zu erreichen, müssen alle Ergebnisse und Fragen entsprechend interpretiert bzw. beantwortet werden. Code alleine ist nicht ausreichend! Die Abgabe erfolgt über Moodle entsprechend der Abgaberichtlinien als pdf und Rmd File. Bitte inkludieren Sie namentlich alle beteiligten Gruppenmitglieder sowohl im Bericht als auch im Source Code.
Die jeweiligen Datensätze die für diese Übung relevant sind finden Sie ebenfalls in Moodle.

# 1 Clustering - Diabetes[3P]
Verwenden Sie den Datensatz `diabetes_RM.csv`. Der Datensatz enthält fünf Messungen, die an 145 nicht adipösen erwachsenen Patienten durchgeführt wurden (Beschreibung siehe UE4). Reaven und Miller [[ref]](https://doi.org/10.1007/BF00423145) wendeten in Anlehnung an Friedman und Rubin (1967) eine Clusteranalyse auf die drei primären Variablen (`insulin`,`glucose` und `sspg`) an und identifizierten drei Cluster: "normal", "chemical" und "overt" diabetische Probanden. Die Variable `group` enthält die Klassifizierungen der Probanden in diese drei Gruppen und dient hier als Ground Truth.

* Führen Sie eine Clusteranalyse durch. Verwenden Sie eine Clusteranzahl von 3 und vergleichen Sie die Genauigkeit (gegenüber Ground Truth) folgender Cluster-Algorithmen:
    + k-means, k-medoids
    + hierarchisches Clustering
    + hierarchischer k-means
    + Modell-basiertes Clustering
* Stellen Sie die Ergebnisse grafisch dar (Scatter Plot).
* Welches Verfahren ist am besten geeignet?
* Finden Sie für k-means die optimale Anzahl an Cluster, und beurteilen Sie ob sich die Ground Truth Clusterstruktur reproduzieren lässt.

```{r}
# Load the data
diabetes <- read.csv("diabetes_RM.csv", header = TRUE, sep = ",")
groups <- c("normal", "chemical", "overt")



# Scale the selected columns
diabetes_scaled_cols <- scale(diabetes[, c("rw", "fpg", "glucose", "insulin", "sspg")])

# Create a new data frame from the scaled columns
diabetes_scaled_df <- as.data.frame(diabetes_scaled_cols)

# Set the row names of the scaled data frame to match the row names of the original data frame
rownames(diabetes_scaled_df) <- rownames(diabetes)

# Bind the scaled columns with the unscaled columns
diabetes_scaled <- cbind(diabetes_scaled_df, group = diabetes$group)



# Perform k-means clustering
kmeans_result <- kmeans(diabetes_scaled_cols, centers = 3)

# Perform k-medoids clustering
kmedoids_result <- pam(diabetes_scaled_cols, k = 3)

# Perform hierarchical clustering
hclust_result <- cutree(hclust(dist(diabetes_scaled_cols)), k = 3)

# Perform hierarchical k-means clustering
hkmeans_result <-hkmeans(diabetes_scaled_cols, 3)

# Perform model-based clustering
mclust_result <- Mclust(diabetes_scaled_cols, G = 3)



kmeans_accuracy <- calculate_accuracy(diabetes_scaled, kmeans_result$cluster, groups)
kmedoids_accuracy <- calculate_accuracy(diabetes_scaled, kmedoids_result$cluster, groups)
hclust_accuracy <- calculate_accuracy(diabetes_scaled, hclust_result, groups)
hkmeans_accuracy <- calculate_accuracy(diabetes_scaled, hkmeans_result$cluster, groups)
mclust_accuracy <- calculate_accuracy(diabetes_scaled, mclust_result$classification, groups)



# Print the accuracy results
cat("k-means accuracy: ", kmeans_accuracy, "\n")
cat("k-medoids accuracy: ", kmedoids_accuracy, "\n")
cat("Hierarchical clustering accuracy: ", hclust_accuracy, "\n")
cat("Hierarchical k-means accuracy: ", hkmeans_accuracy, "\n")
cat("Model-based clustering accuracy: ", mclust_accuracy, "\n")
```

Grafische Darstellung

```{r}
# Load the data
diabetes <- read.csv("diabetes_RM.csv", header = TRUE, sep = ",")
groups <- c("normal", "chemical", "overt")



# Scale the selected columns
diabetes_scaled_cols <- scale(diabetes[, c("rw", "fpg", "glucose", "insulin", "sspg")])

# Create a new data frame from the scaled columns
diabetes_scaled_df <- as.data.frame(diabetes_scaled_cols)

# Set the row names of the scaled data frame to match the row names of the original data frame
rownames(diabetes_scaled_df) <- rownames(diabetes)

# Bind the scaled columns with the unscaled columns
diabetes_scaled <- cbind(diabetes_scaled_df, group = diabetes$group)




# Visualize the tree
fviz_dend(hkmeans_result, cex = 0.6, palette = "jco", 
          rect = TRUE, rect_border = "jco", rect_fill = TRUE)

diabetes_scaled$group <- as.factor(diabetes_scaled$group)
partimat(group ~ ., data = diabetes_scaled, method = "lda")

ml <- lda(group ~ ., data = diabetes_scaled)

print(ml) 

# Perform PCA
# Using subset
diabetes_scaled <- subset(diabetes_scaled, select = -group)
pca_result <- prcomp(diabetes_scaled, center = TRUE, scale. = TRUE)

# Print summary of the PCA result
summary(pca_result)

# Plot the variance explained by each principal component
plot(pca_result)


# Perform PCA
pca_result <- prcomp(diabetes_scaled[sapply(diabetes_scaled, is.numeric)])

# Plot the correlation circle
fviz_pca_var(pca_result, col.var="contrib", gradient.cols = c("#00AFBB", "#E7B800", "#FC4E07"), repel = TRUE)

# Plot the biplot
fviz_pca_biplot(pca_result, col.var="#2E9FDF", col.ind="#696969")
```



# 2 Clustering - Breast Cancer [4P]
Brustkrebs ist weltweit die häufigste bösartige Erkrankung bei Frauen und eine der Hauptursachen für krebsbedingte Todesfälle sowohl in Entwicklungs- als auch in Industrieländern. Verwenden Sie den Datensatz `breast_cancer.csv`. Die Merkmale werden aus einem digitalisierten Bild eines Feinnadelaspirats einer Brustmasse berechnet. Sie beschreiben Merkmale der im Bild vorhandenen Zellkerne. Das Zielmerkmal erfasst die Prognose gutartig (B) oder bösartig (M) und dient hier als Ground Truth. Achten Sie auf uninformative Features (z.B. ID) und fehlende Daten (Missing Values).

* Führen Sie eine Clusteranalyse durch, um eine etwaige Clusterstruktur zwischen gutartigen und bösartigen Zellen zu identifizieren.
* Vergleichen Sie die Genauigkeit folgender Cluster-Algorithmen:
    + k-means
    + hierarchisches Clustering
    + Modell-basiertes Clustering
    + DBSCAN
* Welches Verfahren ist am besten geeignet?
* Stellen Sie die Ergebnisse grafisch dar (Scatter Plot z.B. radius_mean vs. texture_mean).
* Lässt sich das Ergebnis verbessern, wenn vor dem Clustering der Merkmalsraum mittels PCA reduziert wird? Vergleichen Sie die Ergebnisse mit den vorherigen Resultaten.

```{r}
# Load the data
breast_cancer <- read.csv("breast_cancer.csv", header = TRUE, sep = ",")
str(breast_cancer)
summary(breast_cancer)

# check for missing values
sum(is.na(breast_cancer))

# Preprocess the data
# Remove the diagnosis column (ground truth)
breast_cancer_scaled <- scale(breast_cancer[, -c(1)])
breast_cancer_scaled <- as.data.frame(breast_cancer_scaled)

# Perform k-means clustering
kmeans_result <- kmeans(breast_cancer_scaled, centers = 2, nstart = 12)
groups <- kmeans_result$cluster
groups <- car::recode(groups, "1='M'; 2='B'", as.factor = TRUE)

table(breast_cancer$diagnosis, groups)
acc_kmeans <- mean(breast_cancer$diagnosis==groups)

cat("Accuracy of k-means clustering: ", acc_kmeans, "\n")

# Visualize the clusters (radius_mean vs. texture_mean)
ggplot(breast_cancer, aes(x = texture_mean, y = radius_mean, color = groups)) +
  geom_point() +
  labs(title = "k-means Clustering", color = "Cluster") +
  theme_minimal()

# Perform k-medoids clustering (PAM)
ncl.pam<-cluster::pam(breast_cancer_scaled,k = 2)

groups<-ncl.pam$clustering
groups

groups<-car::recode(groups,recodes="1='M';2='B'",as.factor = T)
acc_kmediod <- mean(breast_cancer$diagnosis==groups)

# Visualize the clusters (area_mean vs. smoothness_mean)
ggplot(breast_cancer, aes(x = area_mean, y = smoothness_mean, color = groups)) +
  geom_point() +
  labs(title = "k-mediods Clustering", color = "Cluster") +
  theme_minimal()

```

Interpretation: Die k-means-Clustering-Methode hat eine Genauigkeit von 0,9103, was bedeutet, dass 91% der Daten dem korrekten Cluster zugeordnet wurden. Die Genauigkeit kann in unserem Fall ermittelt werden, da wir die Ground-Truth-Informationen haben.
Die Visualisierung anhand der Merkmale `texture_mean` und `radius_mean` zeigt, dass die Cluster stark überlappen und diese zufällig gewählten Merkmale eine geringe Trennschärfe aufweisen.

Beim k-medoids-Clustering beträgt die Genauigkeit 0,8910. Im Vergleich zu k-means ist die Genauigkeit etwas niedriger, aber immer noch relativ hoch. Die Visualisierung anhand der Merkmale `area_mean` und `smoothness_mean` zeigt ebenfalls eine starke Überlappung der Cluster.

```{r}
# Perform hierarchical clustering
hclust <- hclust(dist(breast_cancer_scaled), method = "ward.D2")
plot(hclust,cex=0.6, hang = -1)
# Cluster einzeichnen
rect.hclust(hclust, k = 2, border = "red")
# Cluster zuweisen
groups <- cutree(hclust, k = 2)
groups <- car::recode(groups, "1='M'; 2='B'", as.factor = TRUE)

acc_hclust <- mean(breast_cancer$diagnosis==groups)

```
Das hierarchische Clustering hat erfolgreich zwei Hauptcluster identifiziert, die mit einer Genauigkeit von 88% den tatsächlichen Diagnosen (benign vs. malignant) entsprechen. Dies deutet darauf hin, dass durch hierarchisches Clustering eine klare Trennung der Datenpunkte möglicht ist.
Die Genauigkeit ist jedoch etwas niedriger als bei k-means und k-medoids.

```{r}
# Perform model-based clustering
mclust_result <- Mclust(breast_cancer_scaled, G = 2)
groups <- mclust_result$classification
groups <- car::recode(groups, "1='M'; 2='B'", as.factor = TRUE)

acc_mclust <- mean(breast_cancer$diagnosis==groups)

```

Das modellbasierte Clustering hat eine Genauigkeit von 0,8910, was der Genauigkeit des k-mediod-Clustering entspricht. Dies deutet darauf hin, dass das modellbasierte Clustering in diesem Fall ähnlich effektiv ist wie k-medoids. Die Visualisierung zeigt eine klare Trennung der Cluster anhand der Merkmale `texture_mean` und `radius_mean`.

```{r}
# Perform DBSCAN clustering
set.seed(123)
dbscan_result <- dbscan(breast_cancer_scaled, eps = 5, MinPts = 50)
groups <- dbscan_result$cluster
groups <- car::recode(groups, "0='M'; 1='B'", as.factor = TRUE)

acc_dbscan <- mean(breast_cancer$diagnosis==groups)

# Berechnung der k-Nächste-Nachbarn-Distanz für k = MinPts
kNNdistplot(breast_cancer_scaled, k = 5)  # Hier setzen wir k = MinPts (Startwert)
abline(h = 0.5, col = "red", lty = 2)

```

DBSCAN scheint für diesen Datensatz nicht optimal zu sein, um zwei Cluster (benign vs. malignant) zu identifizieren. Unabhängig von den Parametern (eps, MinPts) konnte immer nur ein Cluster und Rauschen identifiziert werden. Die ermittelte Genauigkeit beträgt demnach nur 0.6432.
Alternative Methoden wie k-Means und hierarchisches Clustering könnten somit besser geeignet sein, um die Daten in zwei Hauptcluster zu unterteilen.


```{r}
# Accuracy comparison
accuracy <- c(acc_kmeans, acc_kmediod, acc_hclust, acc_mclust, acc_dbscan)
method <- c("k-means", "k-medoids", "hierarchical", "model-based", "DBSCAN")
accuracy_df <- data.frame(method, accuracy)
accuracy_df

```
Die Untersuchung unterschiedlicher Clustering-Methoden auf den Brustkrebsdatensatz zeigt, dass das k-Means-Verfahren mit einer Genauigkeit von 91% am besten abschneidet. Das k-Medoids-Verfahren und das modellbasierte Clustering folgen dicht dahinter mit einer Genauigkeit von jeweils etwa 89%. Hierarchisches Clustering zeigt ebenfalls gute Ergebnisse mit einer Genauigkeit von 88%. Im Vergleich dazu zeigt DBSCAN eine deutlich geringere Genauigkeit von 64%, was darauf hinweist, dass dieses Verfahren für den gegebenen Datensatz weniger geeignet ist.

Jetzt wird überprüft, ob durch eine vorhergehende PCA eine bessere Trennung der Cluster erreicht werden kann.


```{r}
# Dimensionality Reduction with PCA
pca_result <- prcomp(breast_cancer_scaled, scale. = TRUE)
summary(pca_result)

# create a data frame with the first 10 principal components
pca_data <- data.frame(pca_result$x[, 1:10])

# k-Means Clustering
set.seed(123)
kmeans_pca <- kmeans(pca_data, centers = 2, nstart = 20)
groups.kmeans_pca <- kmeans_pca$cluster
groups.kmeans_pca <- car::recode(groups.kmeans_pca, "1='B'; 2='M'", as.factor = TRUE)

# k-Medoids Clustering
kmedoids_pca <- pam(pca_data, k = 2)
groups.kmedoids_pca <- kmedoids_pca$clustering
groups.kmedoids_pca <- car::recode(groups.kmedoids_pca, "1='M'; 2='B'", as.factor = TRUE)

# Hierarchisches Clustering
dist_pca <- dist(pca_data)
hc_pca <- hclust(dist_pca, method = "ward.D2")
groups.hc_pca <- cutree(hc_pca, k = 2)
groups.hc_pca <- car::recode(groups.hc_pca, "1='M'; 2='B'", as.factor = TRUE)


# Modell-basiertes Clustering
mbc_pca <- Mclust(pca_data, G = 2)
groups.mbc_pca <- mbc_pca$classification
groups.mbc_pca <- car::recode(groups.mbc_pca, "1='M'; 2='B'", as.factor = TRUE)

# DBSCAN Clustering
dbscan_pca <- dbscan(pca_data, eps = 5, MinPts = 50)
groups.dbscan_pca <- dbscan_pca$cluster
groups.dbscan_pca <- car::recode(groups.dbscan_pca, "0='B'; 1='M'", as.factor = TRUE)

# Berechnung der Genauigkeiten
acc_kmeans_pca <- mean(breast_cancer$diagnosis == groups.kmeans_pca)
acc_kmedoids_pca <- mean(breast_cancer$diagnosis == groups.kmedoids_pca)
acc_hc_pca <- mean(breast_cancer$diagnosis == groups.hc_pca)
acc_mbc_pca <- mean(breast_cancer$diagnosis == groups.mbc_pca)
acc_dbscan_pca <- mean(breast_cancer$diagnosis == groups.dbscan_pca)

# Accuracy comparison
accuracy_pca <- c(acc_kmeans_pca, acc_kmedoids_pca, acc_hc_pca, acc_mbc_pca, acc_dbscan_pca)
method_pca <- c("k-means", "k-medoids", "hierarchical", "model-based", "DBSCAN")
accuracy_df_pca <- data.frame(method_pca, accuracy_pca)
accuracy_df_pca

# visualize the clusters of kmeans with PCA - Dimensionality Reduction
fviz_cluster(object=kmeans_pca, data=breast_cancer_scaled,ellipse.type = "norm",repel = F) + ggtitle("k-Means Clustering with PCA")

```
Die Auswirkung der PCA auf die Genauigkeit der Clusteranalyse zeigt große Unterschiede bei den einzelnen Methoden. Während sich die Genauigkeit des k-Means-Verfahrens nicht verbessert hat, zeigt die k-Medoids eine Verbesserung von 89.1% auf 91.38%. Die hierarchische Clusteranalyse zeigt die stärkste Verbesserung, mit einem Sprung von 88% auf 91.92%. Im Gegensatz dazu zeigt das modellbasierte Clustering eine deutliche Verschlechterung der Genauigkeit von 89.1% auf 63.62%. Offenbar ist das modellbasierte Clustering weniger gut geeignet, um die Daten in zwei Hauptcluster zu unterteilen, nachdem die Dimensionalität reduziert wurde. 


# 3 Clustering - Heart Disease Patients [3P]
Verwenden Sie den Datensatz `heart_disease_patients.csv`. Der Datensatz enthält anonymisierte Daten von Patienten, bei denen eine Herzerkrankung diagnostiziert wurde. Patienten mit ähnlichen Merkmalen könnten auf die gleichen Behandlungen ansprechen, und Ärzte könnten davon profitieren, etwas über die Behandlungsergebnisse von Patienten zu erfahren, die denen ähneln, die sie behandeln. Zu diesem Zweck führen Sie bitte eine Clusteranalyse durch. Vergleichen Sie unterschiedliche Algorithmen und versuchen Sie ein bestmögliches Ergebnis zu erreichen. Begründen Sie ihre Entscheidungen. Verwenden Sie nur numerische Merkmale und achten Sie auf uninformative Features und fehlende Daten. Versuchen Sie die resultierenden Cluster zu interpretieren.








