---
title: "Vertiefende statistische Verfahren"
subtitle: "5. Übungsblatt SS 2024"
author:
output:
  pdf_document: default
  html_document:
    df_print: paged
  word_document: default
---

```{r, include=FALSE}
## Run this chunk ALWAYS first !
# Arbeitsverzeichnis für VSC Nutzer korrekt setzen
# Nötige Packages installieren und laden
# Helfer Funktionen für alle Nutzer laden

# Set relative path to target working directory
rel_path_to_target_dir <- "ue5"
# Helper file name
rel_path_from_target_dir_to_helper_file <- "helper.R"

# Check if the code is run in RStudio
checkIDEisRStudio <- function() {
  isRStudio <- Sys.getenv("RSTUDIO") == "1"
  if (isRStudio) {
    return(TRUE)
  } else {
    return(FALSE)
  }
}

# Check whether package is already installed, if not install it
load <- function(package_name) {
  if (length(find.package(package_name, quiet = TRUE)) == 0) {
    # Set the CRAN mirror
    options(repos = c(CRAN = "https://cran.wu.ac.at/"))
    install.packages(package_name)
  }
  suppressWarnings(library(package_name, character.only = TRUE))
}

# The working directory is only changed if the code is NOT run in RStudio
if (!checkIDEisRStudio()) {
  load("here")
  # Change relative path accordingly to your target working directory
  abs_path_to_target_dir <- file.path(here(),rel_path_to_target_dir)
  # Check if target directory exists
  if(dir.exists(abs_path_to_target_dir)){
    setwd(abs_path_to_target_dir)
  }
}

# Load packages
load("clue")
load("cluster")
load("tidyverse")
load("factoextra")
load("clusterCrit")
load("fpc")
load("mclust")
load("dplyr")
load("klaR")
load("gridExtra")
load("ggplot2")
load("dbscan")

# Function to source helper file
load_source <- function() {
    if(!checkIDEisRStudio()){
      if(file.exists(rel_path_from_target_dir_to_helper_file)){
        source(rel_path_from_target_dir_to_helper_file)
      }
    } else {
      helper_file <- basename(rel_path_from_target_dir_to_helper_file)
      if(file.exists(helper_file)){
        source(helper_file)
      }
  }
}
# Apply function to source helper file
load_source()

```



# Allgemeine Information
Alle Aufgaben sind mit R zu lössen, wenn nicht explizit anders angegeben. Die Berechnungen sollen nachvollziehbar und dokumentiert sein. Um die vollständige Punktezahl zu erreichen, müssen alle Ergebnisse und Fragen entsprechend interpretiert bzw. beantwortet werden. Code alleine ist nicht ausreichend! Die Abgabe erfolgt über Moodle entsprechend der Abgaberichtlinien als pdf und Rmd File. Bitte inkludieren Sie namentlich alle beteiligten Gruppenmitglieder sowohl im Bericht als auch im Source Code.
Die jeweiligen Datensätze die für diese Übung relevant sind finden Sie ebenfalls in Moodle.

# 1 Clustering - Diabetes[3P]
Verwenden Sie den Datensatz `diabetes_RM.csv`. Der Datensatz enthält fünf Messungen, die an 145 nicht adipösen erwachsenen Patienten durchgeführt wurden (Beschreibung siehe UE4). Reaven und Miller [[ref]](https://doi.org/10.1007/BF00423145) wendeten in Anlehnung an Friedman und Rubin (1967) eine Clusteranalyse auf die drei primären Variablen (`insulin`,`glucose` und `sspg`) an und identifizierten drei Cluster: "normal", "chemical" und "overt" diabetische Probanden. Die Variable `group` enthält die Klassifizierungen der Probanden in diese drei Gruppen und dient hier als Ground Truth.

* Führen Sie eine Clusteranalyse durch. Verwenden Sie eine Clusteranzahl von 3 und vergleichen Sie die Genauigkeit (gegenüber Ground Truth) folgender Cluster-Algorithmen:
    + k-means, k-medoids
    + hierarchisches Clustering
    + hierarchischer k-means
    + Modell-basiertes Clustering

```{r}
load_source()

# Load the data
diabetes <- read.csv("diabetes_RM.csv", header = TRUE, sep = ",")
groups <- c("normal", "chemical", "overt")



# Scale the selected columns
diabetes_scaled_cols <- scale(diabetes[, c("rw", "fpg", "glucose", "insulin", "sspg")])

# Create a new data frame from the scaled columns
diabetes_scaled_df <- as.data.frame(diabetes_scaled_cols)

# Set the row names of the scaled data frame to match the row names of the original data frame
rownames(diabetes_scaled_df) <- rownames(diabetes)

# Bind the scaled columns with the unscaled columns
diabetes_scaled <- cbind(diabetes_scaled_df, group = diabetes$group)



# Perform k-means clustering
kmeans_result <- kmeans(diabetes_scaled_cols, centers = 3)

# Perform k-medoids clustering
kmedoids_result <- pam(diabetes_scaled_cols, k = 3)

# Perform hierarchical clustering
hclust_result <- cutree(hclust(dist(diabetes_scaled_cols)), k = 3)

# Perform hierarchical k-means clustering
hkmeans_result <-hkmeans(diabetes_scaled_cols, 3)

# Perform model-based clustering
mclust_result <- Mclust(diabetes_scaled_cols, G = 3)



kmeans_cluster <- kmeans_result$cluster
kmedoids_cluster <- kmedoids_result$cluster
hclust_cluster <- hclust_result
hkmeans_cluster <- hkmeans_result$cluster
mclust_cluster <- mclust_result$classification



# Create a named vector for recoding
recode_vector <- setNames(1:length(groups), groups)

# Recode the 'group' variable to the matching cluster
ground_truth <- recode(diabetes$group, !!!recode_vector)

#ground_truth <- diabetes$group

# Create a list of the cluster results
cluster_list <- list(ground_truth = ground_truth,
                     kmeans = kmeans_cluster, 
                     kmedoids = kmedoids_cluster, 
                     hclust = hclust_cluster, 
                     hkmeans = hkmeans_cluster, 
                     mclust = mclust_cluster)



kmeans_accuracy <- calculate_accuracy(diabetes_scaled, kmeans_cluster, groups)
kmedoids_accuracy <- calculate_accuracy(diabetes_scaled, kmedoids_cluster, groups)
hclust_accuracy <- calculate_accuracy(diabetes_scaled, hclust_cluster, groups)
hkmeans_accuracy <- calculate_accuracy(diabetes_scaled, hkmeans_cluster, groups)
mclust_accuracy <- calculate_accuracy(diabetes_scaled, mclust_cluster, groups)


# Put the results into a list
accuracy_results <- list(
  ground_truth = 1,
  kmeans = kmeans_accuracy,
  kmedoids = kmedoids_accuracy,
  hclust = hclust_accuracy,
  hkmeans = hkmeans_accuracy,
  mclust = mclust_accuracy
)



# Print the accuracy results
cat("k-means accuracy: ", kmeans_accuracy, "\n")
cat("k-medoids accuracy: ", kmedoids_accuracy, "\n")
cat("Hierarchical clustering accuracy: ", hclust_accuracy, "\n")
cat("Hierarchical k-means accuracy: ", hkmeans_accuracy, "\n")
cat("Model-based clustering accuracy: ", mclust_accuracy, "\n")
```

* Welches Verfahren ist am besten geeignet?

Model-based Clustering erreicht mit etwa 86% die höchste Genauigkeit. 
Auf dem zweiten Platz liegen gleich auf das k-means Clustering und das hierarchische k-means Clustering mit etwa 78% Genauigkeit.
Es folgen mit etwa 75% Genauigkeit das k-medoids Clustering und das hierarchische Clustering.

* Stellen Sie die Ergebnisse grafisch dar (Scatter Plot).

```{r}
# Load the data
diabetes <- read.csv("diabetes_RM.csv", header = TRUE, sep = ",")
groups <- c("normal", "chemical", "overt")



# Scale the selected columns
diabetes_scaled_cols <- scale(diabetes[, c("rw", "fpg", "glucose", "insulin", "sspg")])

# Create a new data frame from the scaled columns
diabetes_scaled_df <- as.data.frame(diabetes_scaled_cols)

# Set the row names of the scaled data frame to match the row names of the original data frame
rownames(diabetes_scaled_df) <- rownames(diabetes)

# Bind the scaled columns with the unscaled columns
diabetes_scaled <- cbind(diabetes_scaled_df, group = diabetes$group)


#------------------------------------------------------------------------------------------
# Dendrogram

# Visualize the tree
fviz_dend(hkmeans_result, cex = 0.6, palette = "jco", 
          rect = TRUE, rect_border = "jco", rect_fill = TRUE)


#------------------------------------------------------------------------------------------
# Perform LDA

diabetes_scaled$group <- as.factor(diabetes_scaled$group)

# Partition plot
partimat(group ~ ., data = diabetes_scaled, method = "lda")

ml <- lda(group ~ ., data = diabetes_scaled)

print(ml) 

#------------------------------------------------------------------------------------------
# Perform PCA
# Using subset
diabetes_scaled <- subset(diabetes_scaled, select = -group)
pca_result <- prcomp(diabetes_scaled, center = TRUE, scale. = TRUE)

# Print summary of the PCA result
summary(pca_result)

# Plot the variance explained by each principal component
plot(pca_result)


# Perform PCA
pca_result <- prcomp(diabetes_scaled[sapply(diabetes_scaled, is.numeric)])

# Plot the correlation circle
fviz_pca_var(pca_result, col.var="contrib", gradient.cols = c("#00AFBB", "#E7B800", "#FC4E07"), repel = TRUE)

# Plot the biplot
fviz_pca_biplot(pca_result, col.var="#2E9FDF", col.ind="#696969")
```

Die LDA zeigt, dass fpg und glucose sowohl zu LD1 und LD2 am stärksten beitragen (d.h. die höchsten Absolutbeträge aufweisen).
Die PCA bestätigt dies, da fpg und glucose die stärksten Beiträge zu PC1 und PC2 liefern.
Deshalb werden die 2-D Scatter plots für fpg und glucose erstellt.

```{r}
load_source()

# Load the data
diabetes <- read.csv("diabetes_RM.csv", header = TRUE, sep = ",")
groups <- c("normal", "chemical", "overt")



# Scale the selected columns
diabetes_scaled_cols <- scale(diabetes[, c("rw", "fpg", "glucose", "insulin", "sspg")])

# Create a new data frame from the scaled columns
diabetes_scaled_df <- as.data.frame(diabetes_scaled_cols)

# Set the row names of the scaled data frame to match the row names of the original data frame
rownames(diabetes_scaled_df) <- rownames(diabetes)

# Bind the scaled columns with the unscaled columns
diabetes_scaled <- cbind(diabetes_scaled_df, group = diabetes$group)

ignore <- TRUE
# Loop over the list and create a scatter plot for each set of cluster labels
for (name in names(cluster_list)) {
  if(name == "hclust") {
    ignore <- FALSE
  }
  plot(create_scatter_plot_with_accuracy(diabetes_scaled,
      cluster_list[[name]], name, accuracy_results[[name]],
      groups,
      ignore))

  ignore <- TRUE
}
```

* Finden Sie für k-means die optimale Anzahl an Cluster, und beurteilen Sie ob sich die Ground Truth Clusterstruktur reproduzieren lässt.

```{r}
load_source()

# Load the data
diabetes <- read.csv("diabetes_RM.csv", header = TRUE, sep = ",")
groups <- c("normal", "chemical", "overt")



# Scale the selected columns
diabetes_scaled_cols <- scale(diabetes[, c("rw", "fpg", "glucose", "insulin", "sspg")])

# Create a new data frame from the scaled columns
diabetes_scaled_df <- as.data.frame(diabetes_scaled_cols)

# Set the row names of the scaled data frame to match the row names of the original data frame
rownames(diabetes_scaled_df) <- rownames(diabetes)

# Bind the scaled columns with the unscaled columns
diabetes_scaled <- cbind(diabetes_scaled_df, group = diabetes$group)


#------------------------------------------------------------------------------------------

n = 6
set.seed(123)
sse <- numeric(n)
cluster_list <- list()
kmeans_result_list <- list()

for(k in 1:n) {
  kmeans_result <- kmeans(diabetes_scaled_cols, centers = k)
  sse[k] <- kmeans_result$tot.withinss

  cluster_list[[k]] <- kmeans_result$cluster
  kmeans_result_list[[k]] <- kmeans_result
}

#------------------------------------------------------------------------------------------
# Plot the SSE/WSS

# Determine the optimal number of clusters using SSE
plot(1:n, sse, type = "b", xlab = "Number of clusters (k)", ylab = "Sum of Squared Errors (SSE)")

# Alternaitvely, determine the optimal number of clusters using the within-cluster sum of squares (WSS)
# Both methods should give the same result
fviz_nbclust(x = diabetes_scaled_cols, FUNcluster = kmeans, method = "wss", k.max = n)

#------------------------------------------------------------------------------------------
# Visualize the k-means clustering results

# Depiction 1
plot_list <- list()

for(k in 1:n) {
  # Generate the plot and store it in the list
  plot_list[[k]] <- create_scatter_plot(diabetes_scaled, cluster_list[[k]], groups)
}

# Combine all the plots into a single plot
grid.arrange(grobs = plot_list, ncol = 2)


# Depiction 2
plot_list <- list()

for(k in 2:n) {
  # Visualize kmeans clustering
  plot_list[[k]] <- fviz_cluster(kmeans_result_list[[k]], diabetes_scaled_cols, ellipse.type = "norm")+
    theme_minimal()
}

# Combine all the plots into a single plot
grid.arrange(grobs = plot_list, ncol = 2)
```

```{r}
set.seed(123)

n = 6
kmeans_result_list <- list()
cluster_list <- list()
silhouette_list <- list()
silhouette_score <- numeric(n)

for(k in 2:n) { # silhouette score is undefined for k = 1
  kmeans_result <- kmeans(diabetes_scaled_cols, centers = k)
  cluster_stats <- cluster.stats(dist(diabetes_scaled_cols), kmeans_result$cluster)
  silhouette_values <- silhouette(kmeans_result$cluster, dist(diabetes_scaled_cols))
  silhouette_score[k] <- mean(cluster_stats$avg.silwidth)
  kmeans_result_list[[k]] <- kmeans_result
  cluster_list[[k]] <- kmeans_result$cluster
  silhouette_list[[k]] <- fviz_silhouette(silhouette_values)
}

# Find the number of clusters that gives the highest silhouette score
best_k <- which.max(silhouette_score)

# Print the best number of clusters
print(paste("Best number of clusters (k):", best_k))

#------------------------------------------------------------------------------------------
# Plot the silhouette scores

# Determine the optimal number of clusters using the silhouette score
plot(2:n, silhouette_score[2:n], type = "b", xlab = "Number of clusters (k)", ylab = "Average Silhouette Width")


# Alternatively, determine the optimal number of clusters using the silhouette method
# Both methods should give the same result
fviz_nbclust(x = diabetes_scaled_cols, FUNcluster = kmeans, method = "silhouette", k.max = n)

#------------------------------------------------------------------------------------------
# Silhouette plots

# Initialize an empty list to store the plots
plot_list <- list()

for(k in 2:n) {
  # Visualize kmeans clustering
  # Print the silhouette plots for each number of clusters
  plot_list[[k]] <- silhouette_list[[k]]
}
  

# Combine all the plots into a single plot
grid.arrange(grobs = plot_list, ncol = 2)
```

Bestimmung des optimalen k-Werts für k-Means-Clustering mit Hilfe des des Silhouettenkoeffizienten.
Laut dem Silhouettenkoeffizienten ist der optimale k-Wert 2.



# 2 Clustering - Breast Cancer [4P]
Brustkrebs ist weltweit die häufigste bösartige Erkrankung bei Frauen und eine der Hauptursachen für krebsbedingte Todesfälle sowohl in Entwicklungs- als auch in Industrieländern. Verwenden Sie den Datensatz `breast_cancer.csv`. Die Merkmale werden aus einem digitalisierten Bild eines Feinnadelaspirats einer Brustmasse berechnet. Sie beschreiben Merkmale der im Bild vorhandenen Zellkerne. Das Zielmerkmal erfasst die Prognose gutartig (B) oder bösartig (M) und dient hier als Ground Truth. Achten Sie auf uninformative Features (z.B. ID) und fehlende Daten (Missing Values).

* Führen Sie eine Clusteranalyse durch, um eine etwaige Clusterstruktur zwischen gutartigen und bösartigen Zellen zu identifizieren.
* Vergleichen Sie die Genauigkeit folgender Cluster-Algorithmen:
    + k-means
    + hierarchisches Clustering
    + Modell-basiertes Clustering
    + DBSCAN
* Welches Verfahren ist am besten geeignet?
* Stellen Sie die Ergebnisse grafisch dar (Scatter Plot z.B. radius_mean vs. texture_mean).
* Lässt sich das Ergebnis verbessern, wenn vor dem Clustering der Merkmalsraum mittels PCA reduziert wird? Vergleichen Sie die Ergebnisse mit den vorherigen Resultaten.

```{r}
# Load the data
breast_cancer <- read.csv("breast_cancer.csv", header = TRUE, sep = ",")
str(breast_cancer)
summary(breast_cancer)

# check for missing values
sum(is.na(breast_cancer))

# Preprocess the data
# Remove the diagnosis column (ground truth)
breast_cancer_scaled <- scale(breast_cancer[, -c(1)])
breast_cancer_scaled <- as.data.frame(breast_cancer_scaled)

# Perform k-means clustering
kmeans_result <- kmeans(breast_cancer_scaled, centers = 2, nstart = 12)
groups <- kmeans_result$cluster
groups <- car::recode(groups, "1='M'; 2='B'", as.factor = TRUE)

table(breast_cancer$diagnosis, groups)
acc_kmeans <- mean(breast_cancer$diagnosis==groups)

cat("Accuracy of k-means clustering: ", acc_kmeans, "\n")

# Visualize the clusters (radius_mean vs. texture_mean)
ggplot(breast_cancer, aes(x = texture_mean, y = radius_mean, color = groups)) +
  geom_point() +
  labs(title = "k-means Clustering", color = "Cluster") +
  theme_minimal()

# Perform k-medoids clustering (PAM)
ncl.pam<-cluster::pam(breast_cancer_scaled,k = 2)

groups<-ncl.pam$clustering
groups

groups<-car::recode(groups,recodes="1='M';2='B'",as.factor = T)
acc_kmediod <- mean(breast_cancer$diagnosis==groups)

# Visualize the clusters (area_mean vs. smoothness_mean)
ggplot(breast_cancer, aes(x = area_mean, y = smoothness_mean, color = groups)) +
  geom_point() +
  labs(title = "k-mediods Clustering", color = "Cluster") +
  theme_minimal()

```

Interpretation: Die k-means-Clustering-Methode hat eine Genauigkeit von 0,9103, was bedeutet, dass 91% der Daten dem korrekten Cluster zugeordnet wurden. Die Genauigkeit kann in unserem Fall ermittelt werden, da wir die Ground-Truth-Informationen haben.
Die Visualisierung anhand der Merkmale `texture_mean` und `radius_mean` zeigt, dass die Cluster stark überlappen und diese zufällig gewählten Merkmale eine geringe Trennschärfe aufweisen.

Beim k-medoids-Clustering beträgt die Genauigkeit 0,8910. Im Vergleich zu k-means ist die Genauigkeit etwas niedriger, aber immer noch relativ hoch. Die Visualisierung anhand der Merkmale `area_mean` und `smoothness_mean` zeigt ebenfalls eine starke Überlappung der Cluster.

```{r}
# Perform hierarchical clustering
hclust <- hclust(dist(breast_cancer_scaled), method = "ward.D2")
plot(hclust,cex=0.6, hang = -1)
# Cluster einzeichnen
rect.hclust(hclust, k = 2, border = "red")
# Cluster zuweisen
groups <- cutree(hclust, k = 2)
groups <- car::recode(groups, "1='M'; 2='B'", as.factor = TRUE)

acc_hclust <- mean(breast_cancer$diagnosis==groups)

```
Das hierarchische Clustering hat erfolgreich zwei Hauptcluster identifiziert, die mit einer Genauigkeit von 88% den tatsächlichen Diagnosen (benign vs. malignant) entsprechen. Dies deutet darauf hin, dass durch hierarchisches Clustering eine klare Trennung der Datenpunkte möglicht ist.
Die Genauigkeit ist jedoch etwas niedriger als bei k-means und k-medoids.

```{r}
# Perform model-based clustering
mclust_result <- Mclust(breast_cancer_scaled, G = 2)
groups <- mclust_result$classification
groups <- car::recode(groups, "1='M'; 2='B'", as.factor = TRUE)

acc_mclust <- mean(breast_cancer$diagnosis==groups)

```

Das modellbasierte Clustering hat eine Genauigkeit von 0,8910, was der Genauigkeit des k-mediod-Clustering entspricht. Dies deutet darauf hin, dass das modellbasierte Clustering in diesem Fall ähnlich effektiv ist wie k-medoids. Die Visualisierung zeigt eine klare Trennung der Cluster anhand der Merkmale `texture_mean` und `radius_mean`.

```{r}
# Perform DBSCAN clustering
set.seed(123)
dbscan_result <- dbscan(breast_cancer_scaled, eps = 5, MinPts = 50)
groups <- dbscan_result$cluster
groups <- car::recode(groups, "0='M'; 1='B'", as.factor = TRUE)

acc_dbscan <- mean(breast_cancer$diagnosis==groups)

# Berechnung der k-Nächste-Nachbarn-Distanz für k = MinPts
kNNdistplot(breast_cancer_scaled, k = 5)  # Hier setzen wir k = MinPts (Startwert)
abline(h = 0.5, col = "red", lty = 2)

```

DBSCAN scheint für diesen Datensatz nicht optimal zu sein, um zwei Cluster (benign vs. malignant) zu identifizieren. Unabhängig von den Parametern (eps, MinPts) konnte immer nur ein Cluster und Rauschen identifiziert werden. Die ermittelte Genauigkeit beträgt demnach nur 0.6432.
Alternative Methoden wie k-Means und hierarchisches Clustering könnten somit besser geeignet sein, um die Daten in zwei Hauptcluster zu unterteilen.


```{r}
# Accuracy comparison
accuracy <- c(acc_kmeans, acc_kmediod, acc_hclust, acc_mclust, acc_dbscan)
method <- c("k-means", "k-medoids", "hierarchical", "model-based", "DBSCAN")
accuracy_df <- data.frame(method, accuracy)
accuracy_df

```
Die Untersuchung unterschiedlicher Clustering-Methoden auf den Brustkrebsdatensatz zeigt, dass das k-Means-Verfahren mit einer Genauigkeit von 91% am besten abschneidet. Das k-Medoids-Verfahren und das modellbasierte Clustering folgen dicht dahinter mit einer Genauigkeit von jeweils etwa 89%. Hierarchisches Clustering zeigt ebenfalls gute Ergebnisse mit einer Genauigkeit von 88%. Im Vergleich dazu zeigt DBSCAN eine deutlich geringere Genauigkeit von 64%, was darauf hinweist, dass dieses Verfahren für den gegebenen Datensatz weniger geeignet ist.

Jetzt wird überprüft, ob durch eine vorhergehende PCA eine bessere Trennung der Cluster erreicht werden kann.


```{r}
# Dimensionality Reduction with PCA
pca_result <- prcomp(breast_cancer_scaled, scale. = TRUE)
summary(pca_result)

# create a data frame with the first 10 principal components
pca_data <- data.frame(pca_result$x[, 1:10])

# k-Means Clustering
set.seed(123)
kmeans_pca <- kmeans(pca_data, centers = 2, nstart = 20)
groups.kmeans_pca <- kmeans_pca$cluster
groups.kmeans_pca <- car::recode(groups.kmeans_pca, "1='B'; 2='M'", as.factor = TRUE)

# k-Medoids Clustering
kmedoids_pca <- pam(pca_data, k = 2)
groups.kmedoids_pca <- kmedoids_pca$clustering
groups.kmedoids_pca <- car::recode(groups.kmedoids_pca, "1='M'; 2='B'", as.factor = TRUE)

# Hierarchisches Clustering
dist_pca <- dist(pca_data)
hc_pca <- hclust(dist_pca, method = "ward.D2")
groups.hc_pca <- cutree(hc_pca, k = 2)
groups.hc_pca <- car::recode(groups.hc_pca, "1='M'; 2='B'", as.factor = TRUE)


# Modell-basiertes Clustering
mbc_pca <- Mclust(pca_data, G = 2)
groups.mbc_pca <- mbc_pca$classification
groups.mbc_pca <- car::recode(groups.mbc_pca, "1='M'; 2='B'", as.factor = TRUE)

# DBSCAN Clustering
dbscan_pca <- dbscan(pca_data, eps = 5, MinPts = 50)
groups.dbscan_pca <- dbscan_pca$cluster
groups.dbscan_pca <- car::recode(groups.dbscan_pca, "0='B'; 1='M'", as.factor = TRUE)

# Berechnung der Genauigkeiten
acc_kmeans_pca <- mean(breast_cancer$diagnosis == groups.kmeans_pca)
acc_kmedoids_pca <- mean(breast_cancer$diagnosis == groups.kmedoids_pca)
acc_hc_pca <- mean(breast_cancer$diagnosis == groups.hc_pca)
acc_mbc_pca <- mean(breast_cancer$diagnosis == groups.mbc_pca)
acc_dbscan_pca <- mean(breast_cancer$diagnosis == groups.dbscan_pca)

# Accuracy comparison
accuracy_pca <- c(acc_kmeans_pca, acc_kmedoids_pca, acc_hc_pca, acc_mbc_pca, acc_dbscan_pca)
method_pca <- c("k-means", "k-medoids", "hierarchical", "model-based", "DBSCAN")
accuracy_df_pca <- data.frame(method_pca, accuracy_pca)
accuracy_df_pca

# visualize the clusters of kmeans with PCA - Dimensionality Reduction
fviz_cluster(object=kmeans_pca, data=breast_cancer_scaled,ellipse.type = "norm",repel = F) + ggtitle("k-Means Clustering with PCA")

```

Die Auswirkung der PCA auf die Genauigkeit der Clusteranalyse zeigt große Unterschiede bei den einzelnen Methoden. Während sich die Genauigkeit des k-Means-Verfahrens nicht verbessert hat, zeigt die k-Medoids eine Verbesserung von 89.1% auf 91.38%. Die hierarchische Clusteranalyse zeigt die stärkste Verbesserung, mit einem Sprung von 88% auf 91.92%. Im Gegensatz dazu zeigt das modellbasierte Clustering eine deutliche Verschlechterung der Genauigkeit von 89.1% auf 63.62%. Offenbar ist das modellbasierte Clustering weniger gut geeignet, um die Daten in zwei Hauptcluster zu unterteilen, nachdem die Dimensionalität reduziert wurde. 


# 3 Clustering - Heart Disease Patients [3P]
Verwenden Sie den Datensatz `heart_disease_patients.csv`. Der Datensatz enthält anonymisierte Daten von Patienten, bei denen eine Herzerkrankung diagnostiziert wurde. Patienten mit ähnlichen Merkmalen könnten auf die gleichen Behandlungen ansprechen, und Ärzte könnten davon profitieren, etwas über die Behandlungsergebnisse von Patienten zu erfahren, die denen ähneln, die sie behandeln. Zu diesem Zweck führen Sie bitte eine Clusteranalyse durch. Vergleichen Sie unterschiedliche Algorithmen und versuchen Sie ein bestmögliches Ergebnis zu erreichen. Begründen Sie ihre Entscheidungen. Verwenden Sie nur numerische Merkmale und achten Sie auf uninformative Features und fehlende Daten. Versuchen Sie die resultierenden Cluster zu interpretieren.


```{r}
load_source()

# Load the data
heart_disease_patients_tot <- read.csv("heart_disease_patients.csv")

heart_disease_patients <- subset(heart_disease_patients_tot, select= -c(id,sex,cp,fbs,restecg,exang,slope))
print(heart_disease_patients)

# Perform exploratory data analysis
summary(heart_disease_patients)

# Handle missing data
heart_disease_patients <- na.omit(heart_disease_patients)

# Normalize the numerical features (assuming all features are numerical)
heart_disease_patients_scaled <- scale(heart_disease_patients, center = TRUE)

#------------------------------------------------------------------------------------------
# Perform PCA
# Using subset
pca_result <- prcomp(heart_disease_patients_scaled)

# Print summary of the PCA result
summary(pca_result)

# Plot the variance explained by each principal component
plot(pca_result)

# Plot the correlation circle
fviz_pca_var(pca_result, col.var="contrib", gradient.cols = c("#00AFBB", "#E7B800", "#FC4E07"), repel = TRUE)

# Plot the biplot
fviz_pca_biplot(pca_result, col.var="#2E9FDF", col.ind="#696969")

#------------------------------------------------------------------------------------------


# Apply K-Means clustering

data <- pca_result$x

set.seed(123)
kmeans_result <- kmeans(data, centers=3)

# Evaluate the performance
silhouette_score <- cluster.stats(dist(data), kmeans_result$cluster)$avg.silwidth
print(paste("Silhouette Score: ", silhouette_score))

# Interpret the clusters
print(kmeans_result$centers)

plot(create_scatter_plot_pca(data, kmeans_result$cluster, "kmeans"))

```

```{r}
load_source()

# Perform PCA on the scaled data
pca_result <- prcomp(heart_disease_patients_scaled)

# Get the data in the PC space
pc_data <- pca_result$x

# Perform k-means clustering
kmeans_result <- kmeans(pc_data, centers = 3)

# Perform k-medoids clustering
kmedoids_result <- pam(pc_data, k = 3)

# Perform hierarchical clustering
hclust_result <- cutree(hclust(dist(pc_data)), k = 3)

# Perform hierarchical k-means clustering
hkmeans_result <- hkmeans(pc_data, 3)

# Perform model-based clustering
mclust_result <- Mclust(pc_data, G = 3)

kmeans_cluster <- kmeans_result$cluster
kmedoids_cluster <- kmedoids_result$cluster
hclust_cluster <- hclust_result
hkmeans_cluster <- hkmeans_result$cluster
mclust_cluster <- mclust_result$classification

# Create a list of the cluster results
cluster_list <- list(kmeans = kmeans_cluster, 
                     kmedoids = kmedoids_cluster, 
                     hclust = hclust_cluster, 
                     hkmeans = hkmeans_cluster, 
                     mclust = mclust_cluster)


# Iterate over the cluster_list
for(cluster_name in names(cluster_list)) {
  # Get the cluster
  cluster <- cluster_list[[cluster_name]]
  
  # Call the create_scatter_plot_pca function
  print(create_scatter_plot_pca(pc_data, cluster, cluster_name))
}
```


```{r}
load_source()

data <- pc_data


n = 6
set.seed(123)
sse <- numeric(n)
cluster_list <- list()
kmeans_result_list <- list()

for(k in 1:n) {
  kmeans_result <- kmeans(data, centers = k)
  sse[k] <- kmeans_result$tot.withinss

  cluster_list[[k]] <- kmeans_result$cluster
  kmeans_result_list[[k]] <- kmeans_result
}

#------------------------------------------------------------------------------------------

# Determine the optimal number of clusters using the within-cluster sum of squares (WSS)
fviz_nbclust(x = data, FUNcluster = kmeans, method = "wss", k.max = n)

# Determine the optimal number of clusters using the silhouette method
fviz_nbclust(x = data, FUNcluster = kmeans, method = "silhouette", k.max = n)


#------------------------------------------------------------------------------------------
# Visualize the k-means clustering results

# Depiction 1
plot_list <- list()

for(k in 1:n) {
  # Generate the plot and store it in the list
  plot_list[[k]] <- create_scatter_plot_pca( data, cluster_list[[k]], names(cluster_list)[k] )
}

# Combine all the plots into a single plot
grid.arrange(grobs = plot_list, ncol = 2)


# Depiction 2
plot_list <- list()

for(k in 2:n) {
  # Visualize kmeans clustering
  plot_list[[k]] <- fviz_cluster(kmeans_result_list[[k]], data = data[, c(1,2)], ellipse.type = "norm")+
    theme_minimal()
}

# Combine all the plots into a single plot
grid.arrange(grobs = plot_list, ncol = 2)
```



```{r}
load_source()
# Define the list of methods
methods <- list("kmeans" = kmeans, "pam" = pam)  # pam is the function for k-medoids clustering in the cluster package

# Calculate the clusters
clusters <- calculate_clusters(n = 6, data = data, methods = methods)
```

```{r}
# Perform PCA on the scaled data
pca_result <- prcomp(data)

# Get the data in the PC space
pc_data <- pca_result$x

# Perform k-means clustering in the PC space
kmeans_result <- kmeans(pc_data, centers = 3)

# Get the cluster labels
cluster_labels <- kmeans_result$cluster
```